---
# Health Maintenance Playbook
# ---------------------------
# Comprehensive environment health monitor. Runs checks across all SSH-accessible
# hosts and the Semaphore/DB environment, then sends Discord alerts and logs results.
#
# Play 1 (localhost):  Init, load state, Semaphore API check, stale backup DB check,
#                      backup size anomaly, failed maintenance DB check,
#                      stale maintenance check, MariaDB health, WAN connectivity,
#                      appliance reachability
# Play 2 (SSH hosts):  Per-host system metrics â€” disk, memory, CPU, journal errors,
#                      OOM kills, Docker health, SMART disk health, PVE cluster quorum,
#                      Ceph health (PVE only), SSL certificate expiry, NTP sync,
#                      DNS resolution, unRAID array, PBS datastore, ZFS pool,
#                      BTRFS health, Docker HTTP
# Play 3 (localhost):  Aggregate findings, unreachable host alerting,
#                      Discord alerts per host, DB logging, save state
#
# Hosts covered by Play 2: defined by health_check_groups in vars/semaphore_check.yaml
# Appliances (pikvm, unifi_network, unifi_protect) â€” covered via stale backup detection
#
# Required variables (vars/secrets.yaml):
#   semaphore_api_token, semaphore_host_url
#   discord_webhook_id, discord_webhook_token
#   logging_db_host, logging_db_port, logging_db_user, logging_db_password, logging_db_name
#   logging_domain_local, logging_domain_ext
#
# Threshold variables (vars/semaphore_check.yaml â€” all have defaults):
#   health_disk_warn_pct, health_disk_crit_pct, health_mem_warn_pct
#   health_cpu_load_multiplier, health_journal_errors_max
#   health_oom_kills_max, health_backup_stale_days
#   health_ssl_warn_days, health_ssl_crit_days
#   health_maintenance_stale_days, health_db_connections_warn_pct
#   health_wan_url, health_ntp_max_offset_ms, health_dns_hostname
#   health_backup_size_min_pct, appliance_check_hosts, appliance_check_port

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PLAY 1 â€” LOCALHOST: INIT + SEMAPHORE/DB CHECKS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
- name: Check health â€” run DB and API checks
  hosts: localhost
  gather_facts: true
  vars_files:
    - vars/secrets.yaml
    - vars/semaphore_check.yaml
  vars:
    project_id: "{{ semaphore_project_id }}"
    task_count: 20
    maintenance_name: "Semaphore"
    maintenance_type: "Local"
    maintenance_subtype: "Health Check"
    maintenance_url: "{{ semaphore_ext_url }}"
    maintenance_description: "Scheduled health monitoring checks"

  pre_tasks:
    - name: Assert MariaDB logging database is reachable
      include_tasks: tasks/assert_db_connectivity.yaml

  tasks:

    # â”€â”€ INIT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - name: Initialize state
      ansible.builtin.set_fact:
        maintenance_failed: false
        play1_health_results: []   # list of {check_name, status, value, detail}

    - name: Load last check timestamp from DB
      block:
        - name: Query last check time
          vars:
            ansible_python_interpreter: "{{ ansible_playbook_python }}"
          community.mysql.mysql_query:
            login_host: "{{ logging_db_host }}"
            login_port: "{{ logging_db_port }}"
            login_user: "{{ logging_db_user }}"
            login_password: "{{ logging_db_password }}"
            login_db: "{{ logging_db_name }}"
            query: "SELECT DATE_FORMAT(last_check, '%%Y-%%m-%%dT%%H:%%i:%%sZ') AS last_check FROM health_check_state WHERE id = 1"
          register: _state_result
          no_log: true
          changed_when: false
          check_mode: false

        - name: Set last check from DB
          ansible.builtin.set_fact:
            last_check: "{{ _state_result.query_result[0][0].last_check }}"
          when: _state_result.query_result[0] | length > 0

        - name: Set default last check (1 hour ago â€” no DB row)
          ansible.builtin.set_fact:
            last_check: "{{ '%Y-%m-%dT%H:%M:%SZ' | strftime(now(utc=true).timestamp() | int - 3600) }}"
          when: _state_result.query_result[0] | length == 0

    # â”€â”€ CHECK 1: Semaphore failed tasks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - name: Check Semaphore for failed tasks
      block:
        - name: Get recent tasks from Semaphore
          ansible.builtin.uri:
            url: "{{ semaphore_url }}/api/project/{{ project_id }}/tasks/last?count={{ task_count }}"
            method: GET
            headers:
              Authorization: "Bearer {{ semaphore_api_token }}"
              Accept: "application/json"
            return_content: true
            status_code: 200
          register: tasks_response
          retries: 3
          delay: 5
          until: tasks_response is succeeded
          no_log: true

        - name: Parse API response
          ansible.builtin.set_fact:
            tasks_list: "{{ tasks_response.content | from_json }}"

        # Build failure list using a loop so we can normalize each task's 'end'
        # timestamp before comparison. Semaphore may return +00:00 suffix while
        # last_check uses Z â€” both are UTC but sort differently as strings.
        - name: Identify new failed tasks
          ansible.builtin.set_fact:
            new_failures: "{{ new_failures | default([]) + [item] }}"
          loop: "{{ tasks_list | selectattr('status', 'equalto', 'error') | selectattr('end', 'defined') | list }}"
          loop_control:
            label: "Task #{{ item.id }}"
          when: (item.end | regex_replace('\\+00:00$', 'Z')) > last_check

        - name: Initialize new_failures if no error tasks
          ansible.builtin.set_fact:
            new_failures: "{{ new_failures | default([]) }}"

        - name: Show results
          ansible.builtin.debug:
            msg: "Last check: {{ last_check }} | New failures: {{ new_failures | length }}"

        - name: Send Discord alert per failed task
          include_tasks: tasks/notify_discord.yaml
          loop: "{{ new_failures }}"
          loop_control:
            label: "Task #{{ item.id }}"
          when: new_failures | length > 0
          vars:
            discord_title: "ðŸ”´ Task Failed in Semaphore"
            discord_color: "{{ discord_color_failure }}"
            discord_author: "{{ controller_fqdn }}"
            discord_fields:
              - name: "Template"
                value: "{{ item.tpl_alias | default('Unknown') }}"
                inline: true
              - name: "Playbook"
                value: "{{ item.tpl_playbook | default('N/A') }}"
                inline: true
              - name: "Project"
                value: "Project {{ project_id }}"
                inline: true
              - name: "Triggered By"
                value: "{{ item.user_name | default('Scheduler / API') }}"
                inline: true
              - name: "Started"
                value: "{{ item.start | default('N/A') }}"
                inline: true
              - name: "Ended"
                value: "{{ item.end | default('N/A') }}"
                inline: true
              - name: "Task ID"
                value: "[#{{ item.id }}]({{ semaphore_ext_url }}/project/{{ project_id }}/history/{{ item.id }})"
                inline: true
            discord_footer:
              text: "Semaphore Alert"
            discord_timestamp: "{{ item.end | default(item.start) | default(now(utc=true) | string) }}"

        - name: Record Semaphore check result
          ansible.builtin.set_fact:
            play1_health_results: >-
              {{ play1_health_results + [{
                'check_name': 'semaphore_tasks',
                'status': ('critical' if new_failures | length > 0 else 'ok'),
                'value': (new_failures | length | string + ' failed'),
                'detail': (new_failures | map(attribute='tpl_alias') | join(', ') if new_failures | length > 0 else 'no failures')
              }] }}

      rescue:
        - name: Set maintenance failed (Semaphore check error)
          ansible.builtin.set_fact:
            maintenance_failed: true
        - name: Debug check results
          ansible.builtin.debug:
            msg: "CHECK 1 FAILED: Semaphore task check error â€” skipping"

    # â”€â”€ CHECK 2: Stale backups â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - name: Check for stale backups
      block:
        - name: Query for hosts with no backup in last {{ health_backup_stale_days }} days
          vars:
            ansible_python_interpreter: "{{ ansible_playbook_python }}"
          community.mysql.mysql_query:
            login_host: "{{ logging_db_host }}"
            login_port: "{{ logging_db_port }}"
            login_user: "{{ logging_db_user }}"
            login_password: "{{ logging_db_password }}"
            login_db: "{{ logging_db_name }}"
            query: >-
              SELECT CONCAT(hostname, '\t',
              DATE_FORMAT(CONVERT_TZ(MAX(timestamp), '+00:00', %s), '%%m/%%d/%%Y %%l:%%i %%p'), '\t',
              TIMESTAMPDIFF(HOUR, MAX(timestamp), UTC_TIMESTAMP()), 'h ago') AS line
              FROM backups GROUP BY hostname
              HAVING TIMESTAMPDIFF(HOUR, MAX(timestamp), UTC_TIMESTAMP()) > %s
              ORDER BY TIMESTAMPDIFF(HOUR, MAX(timestamp), UTC_TIMESTAMP()) DESC
            positional_args:
              - "{{ display_timezone }}"
              - "{{ health_backup_stale_days * 24 }}"
          register: stale_backup_result
          no_log: true
          changed_when: false
          check_mode: false

        - name: Parse stale backup results
          ansible.builtin.set_fact:
            stale_backup_lines: "{{ stale_backup_result.query_result[0] | map(attribute='line') | list }}"

        - name: Send Discord alert for stale backups
          include_tasks: tasks/notify_discord.yaml
          when: stale_backup_lines | length > 0
          vars:
            discord_title: "âš ï¸ Stale Backup Alert"
            discord_color: "{{ discord_color_warning }}"
            discord_description: "The following hosts have not had a successful backup in over {{ health_backup_stale_days }} days."
            discord_author: "{{ controller_fqdn }}"
            discord_fields:
              - name: "Host / Last backup / Age"
                value: "{{ stale_backup_lines | join('\n') }}"
            discord_footer:
              text: "ansible_logging backup check"
            discord_timestamp: "{{ now(utc=true).strftime('%Y-%m-%dT%H:%M:%SZ') }}"

        - name: Record stale backup check result
          ansible.builtin.set_fact:
            play1_health_results: >-
              {{ play1_health_results + [{
                'check_name': 'stale_backup',
                'status': ('warning' if stale_backup_lines | length > 0 else 'ok'),
                'value': (stale_backup_lines | length | string + ' stale'),
                'detail': (stale_backup_lines | join(' | ') if stale_backup_lines | length > 0 else 'all hosts current')
              }] }}

      rescue:
        - name: Set maintenance failed (stale backup check error)
          ansible.builtin.set_fact:
            maintenance_failed: true
        - name: Debug check results
          ansible.builtin.debug:
            msg: "CHECK 2 FAILED: Stale backup check error â€” skipping"

    # â”€â”€ CHECK 3: Backup size anomaly detection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - name: Check for backup size anomalies
      block:
        - name: Query for anomalously small backups
          vars:
            ansible_python_interpreter: "{{ ansible_playbook_python }}"
          community.mysql.mysql_query:
            login_host: "{{ logging_db_host }}"
            login_port: "{{ logging_db_port }}"
            login_user: "{{ logging_db_user }}"
            login_password: "{{ logging_db_password }}"
            login_db: "{{ logging_db_name }}"
            query: >-
              SELECT b.application, b.hostname, b.file_size,
                     ROUND(avg_tbl.avg_size, 2) AS avg_size
              FROM backups b
              INNER JOIN (
                SELECT application, hostname, AVG(file_size) AS avg_size, COUNT(*) AS cnt
                FROM backups
                WHERE timestamp > UTC_TIMESTAMP() - INTERVAL 30 DAY
                GROUP BY application, hostname
                HAVING cnt >= 3
              ) avg_tbl ON b.application = avg_tbl.application AND b.hostname = avg_tbl.hostname
              WHERE b.id IN (
                SELECT MAX(id) FROM backups GROUP BY application, hostname
              )
              AND b.file_size < avg_tbl.avg_size * %s / 100
            positional_args:
              - "{{ health_backup_size_min_pct }}"
          register: _size_anomaly_result
          check_mode: false
          no_log: true

        - name: Record backup size anomaly results
          ansible.builtin.set_fact:
            play1_health_results: >-
              {{ play1_health_results + [{
                'check_name': 'backup_size_anomaly',
                'status': 'warning' if (_size_anomaly_result.query_result[0] | length > 0) else 'ok',
                'value': (_size_anomaly_result.query_result[0] | length | string) + ' anomalies' if (_size_anomaly_result.query_result[0] | length > 0) else 'normal',
                'detail': _size_anomaly_result.query_result[0] | map(attribute='application') | join(', ') if (_size_anomaly_result.query_result[0] | length > 0) else ''
              }] }}

      rescue:
        - name: Set maintenance failed (backup size anomaly check error)
          ansible.builtin.set_fact:
            maintenance_failed: true
        - name: Debug check results
          ansible.builtin.debug:
            msg: "CHECK 3 FAILED: Backup size anomaly check error â€” skipping"

    # â”€â”€ CHECK 4: Failed maintenance runs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - name: Check for failed maintenance
      block:
        - name: Query maintenance table for failures since last check
          vars:
            ansible_python_interpreter: "{{ ansible_playbook_python }}"
          community.mysql.mysql_query:
            login_host: "{{ logging_db_host }}"
            login_port: "{{ logging_db_port }}"
            login_user: "{{ logging_db_user }}"
            login_password: "{{ logging_db_password }}"
            login_db: "{{ logging_db_name }}"
            query: >-
              SELECT CONCAT(application, ' on ', hostname, ' (', type, '/', subtype, ')') AS line
              FROM maintenance
              WHERE status = 'failed'
              AND timestamp > STR_TO_DATE(%s, '%%Y-%%m-%%dT%%H:%%i:%%sZ')
              ORDER BY timestamp DESC
            positional_args:
              - "{{ last_check }}"
          register: failed_maintenance_result
          no_log: true
          changed_when: false
          check_mode: false

        - name: Parse failed maintenance results
          ansible.builtin.set_fact:
            failed_maintenance_lines: "{{ failed_maintenance_result.query_result[0] | map(attribute='line') | list }}"

        - name: Send Discord alert for failed maintenance runs
          include_tasks: tasks/notify_discord.yaml
          when: failed_maintenance_lines | length > 0
          vars:
            discord_title: "âš ï¸ Failed Maintenance Runs"
            discord_color: "{{ discord_color_warning }}"
            discord_description: "The following maintenance tasks failed since the last health check."
            discord_author: "{{ controller_fqdn }}"
            discord_fields:
              - name: "Failed runs"
                value: "{{ failed_maintenance_lines | join('\n') }}"
            discord_footer:
              text: "ansible_logging maintenance check"
            discord_timestamp: "{{ now(utc=true).strftime('%Y-%m-%dT%H:%M:%SZ') }}"

        - name: Record failed maintenance check result
          ansible.builtin.set_fact:
            play1_health_results: >-
              {{ play1_health_results + [{
                'check_name': 'failed_maintenance',
                'status': ('warning' if failed_maintenance_lines | length > 0 else 'ok'),
                'value': (failed_maintenance_lines | length | string + ' failed'),
                'detail': (failed_maintenance_lines | join(' | ') if failed_maintenance_lines | length > 0 else 'no failures')
              }] }}

      rescue:
        - name: Set maintenance failed (maintenance check error)
          ansible.builtin.set_fact:
            maintenance_failed: true
        - name: Debug check results
          ansible.builtin.debug:
            msg: "CHECK 4 FAILED: Failed maintenance check error â€” skipping"

    # â”€â”€ CHECK 5: Stale maintenance runs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - name: Check for stale maintenance
      block:
        - name: Query for hosts with no successful maintenance in {{ health_maintenance_stale_days }} days
          vars:
            ansible_python_interpreter: "{{ ansible_playbook_python }}"
          community.mysql.mysql_query:
            login_host: "{{ logging_db_host }}"
            login_port: "{{ logging_db_port }}"
            login_user: "{{ logging_db_user }}"
            login_password: "{{ logging_db_password }}"
            login_db: "{{ logging_db_name }}"
            query: >-
              SELECT CONCAT(hostname, ' â€” last: ',
              DATE_FORMAT(CONVERT_TZ(MAX(timestamp), '+00:00', %s), '%%m/%%d %%l:%%i %%p')) AS line
              FROM maintenance WHERE status = 'success'
              GROUP BY hostname
              HAVING MAX(timestamp) < UTC_TIMESTAMP() - INTERVAL %s DAY
              ORDER BY MAX(timestamp) ASC
            positional_args:
              - "{{ display_timezone }}"
              - "{{ health_maintenance_stale_days }}"
          register: stale_maintenance_result
          no_log: true
          changed_when: false
          check_mode: false

        - name: Parse stale maintenance results
          ansible.builtin.set_fact:
            stale_maintenance_lines: "{{ stale_maintenance_result.query_result[0] | map(attribute='line') | list }}"

        - name: Record stale maintenance check result
          ansible.builtin.set_fact:
            play1_health_results: >-
              {{ play1_health_results + [{
                'check_name': 'stale_maintenance',
                'status': ('warning' if stale_maintenance_lines | length > 0 else 'ok'),
                'value': (stale_maintenance_lines | length | string + ' stale'),
                'detail': (stale_maintenance_lines | join(' | ') if stale_maintenance_lines | length > 0 else 'all hosts current')
              }] }}

      rescue:
        - name: Set maintenance failed (stale maintenance check error)
          ansible.builtin.set_fact:
            maintenance_failed: true
        - name: Debug check results
          ansible.builtin.debug:
            msg: "CHECK 5 FAILED: Stale maintenance check error â€” skipping"

    # â”€â”€ CHECK 6: MariaDB internal health â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - name: Check MariaDB health
      block:
        - name: Check MariaDB connection usage
          vars:
            ansible_python_interpreter: "{{ ansible_playbook_python }}"
          community.mysql.mysql_query:
            login_host: "{{ logging_db_host }}"
            login_port: "{{ logging_db_port }}"
            login_user: "{{ logging_db_user }}"
            login_password: "{{ logging_db_password }}"
            login_db: "{{ logging_db_name }}"
            query: "SELECT @@max_connections AS max_conn, (SELECT COUNT(*) FROM information_schema.PROCESSLIST) AS current_conn"
          register: mariadb_conn_result
          no_log: true
          changed_when: false
          check_mode: false

        - name: Calculate connection percentage
          ansible.builtin.set_fact:
            _db_max: "{{ mariadb_conn_result.query_result[0][0].max_conn | int }}"
            _db_current: "{{ mariadb_conn_result.query_result[0][0].current_conn | int }}"

        - name: Compute connection percent
          ansible.builtin.set_fact:
            _db_pct: "{{ ((_db_current | int / _db_max | int) * 100) | round(1) }}"

        - name: Check for crashed tables
          vars:
            ansible_python_interpreter: "{{ ansible_playbook_python }}"
          community.mysql.mysql_query:
            login_host: "{{ logging_db_host }}"
            login_port: "{{ logging_db_port }}"
            login_user: "{{ logging_db_user }}"
            login_password: "{{ logging_db_password }}"
            login_db: "{{ logging_db_name }}"
            query: "SELECT TABLE_NAME FROM information_schema.TABLES WHERE TABLE_SCHEMA = %s AND TABLE_COMMENT LIKE '%%crashed%%'"
            positional_args:
              - "{{ logging_db_name }}"
          register: crashed_tables_result
          no_log: true
          changed_when: false
          check_mode: false

        - name: Parse crashed tables
          ansible.builtin.set_fact:
            _crashed_tables: "{{ crashed_tables_result.query_result[0] | map(attribute='TABLE_NAME') | list }}"

        - name: Record MariaDB health result
          ansible.builtin.set_fact:
            play1_health_results: >-
              {{ play1_health_results + [{
                'check_name': 'mariadb_health',
                'status': (
                  'critical' if _crashed_tables | length > 0
                  else ('warning' if _db_pct | float >= health_db_connections_warn_pct else 'ok')
                ),
                'value': _db_current | string + '/' + _db_max | string + ' connections' + (', ' + _crashed_tables | length | string + ' crashed' if _crashed_tables | length > 0 else ''),
                'detail': (
                  ('crashed: ' + _crashed_tables | join(', ') if _crashed_tables | length > 0 else '')
                  + (' | ' if _crashed_tables | length > 0 and _db_pct | float >= health_db_connections_warn_pct else '')
                  + (_db_pct | string + '% of max_connections' if _db_pct | float >= health_db_connections_warn_pct else '')
                )
              }] }}

      rescue:
        - name: Set maintenance failed (MariaDB health check error)
          ansible.builtin.set_fact:
            maintenance_failed: true
        - name: Debug check results
          ansible.builtin.debug:
            msg: "CHECK 6 FAILED: MariaDB health check error â€” skipping"

    # â”€â”€ CHECK 7: WAN connectivity â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - name: Check WAN connectivity
      block:
        - name: Test outbound internet connectivity
          ansible.builtin.uri:
            url: "{{ health_wan_url }}"
            method: GET
            status_code: 200
            timeout: 10
          register: wan_result
          retries: 3
          delay: 5
          until: wan_result is succeeded

        - name: Record WAN connectivity result
          ansible.builtin.set_fact:
            play1_health_results: >-
              {{ play1_health_results + [{
                'check_name': 'wan_connectivity',
                'status': 'ok',
                'value': 'connected',
                'detail': ''
              }] }}

      rescue:
        - name: Record WAN connectivity failure
          ansible.builtin.set_fact:
            play1_health_results: >-
              {{ play1_health_results + [{
                'check_name': 'wan_connectivity',
                'status': 'critical',
                'value': 'unreachable',
                'detail': 'failed to reach ' + health_wan_url
              }] }}

    # â”€â”€ CHECK 8: Appliance reachability â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Appliances (PiKVM, UDMP, UNVR) lack SSH access so Play 2 can't check them.
    # This TCP connect test provides faster outage detection than stale backup alerts.
    - name: Check appliance reachability
      when: appliance_check_hosts | default([]) | length > 0
      block:
        - name: Test TCP connectivity to appliance hosts
          ansible.builtin.wait_for:
            host: "{{ item }}"
            port: "{{ appliance_check_port | default(443) }}"
            timeout: 5
          loop: "{{ appliance_check_hosts }}"
          loop_control:
            label: "{{ item }}"
          register: _appliance_results
          ignore_errors: true

        - name: Identify unreachable appliances
          ansible.builtin.set_fact:
            _unreachable_appliances: >-
              {{ _appliance_results.results
                 | selectattr('failed', 'defined')
                 | selectattr('failed')
                 | map(attribute='item')
                 | list }}

        - name: Send Discord alert for unreachable appliances
          include_tasks: tasks/notify_discord.yaml
          when: _unreachable_appliances | length > 0
          vars:
            discord_title: "ðŸ”´ Unreachable Appliances"
            discord_color: "{{ discord_color_failure }}"
            discord_description: "The following appliances did not respond to TCP port {{ appliance_check_port | default(443) }}."
            discord_author: "{{ controller_fqdn }}"
            discord_fields:
              - name: "Unreachable"
                value: "{{ _unreachable_appliances | join(', ') }}"
            discord_footer:
              text: "Health Check"
            discord_timestamp: "{{ now(utc=true).strftime('%Y-%m-%dT%H:%M:%SZ') }}"

        - name: Record appliance reachability result
          ansible.builtin.set_fact:
            play1_health_results: >-
              {{ play1_health_results + [{
                'check_name': 'appliance_reachable',
                'status': ('critical' if _unreachable_appliances | length > 0 else 'ok'),
                'value': (_unreachable_appliances | length | string + ' unreachable') if _unreachable_appliances | length > 0 else 'all reachable',
                'detail': _unreachable_appliances | join(', ') if _unreachable_appliances | length > 0 else ''
              }] }}

      rescue:
        - name: Set maintenance failed (appliance check error)
          ansible.builtin.set_fact:
            maintenance_failed: true
        - name: Debug check results
          ansible.builtin.debug:
            msg: "CHECK 8 FAILED: Appliance reachability check error â€” skipping"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PLAY 2 â€” SSH HOSTS: SYSTEM METRICS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
- name: Check health â€” gather per-host metrics
  hosts: "{{ health_check_groups | join(':') }}"
  gather_facts: true
  ignore_unreachable: true
  vars_files:
    - vars/secrets.yaml
    - vars/semaphore_check.yaml
  tasks:

    # If a host is unreachable (ignore_unreachable: true), no tasks run and these
    # vars stay undefined. Play 3 uses `| default(false)` to detect this.
    - name: Initialize host health issue list
      ansible.builtin.set_fact:
        host_health_issues: []   # list of {check_name, status, value, detail}
        host_reachable: true

    # â”€â”€ CHECK 9: Disk space â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - name: Check disk space
      block:
        # Uses df -T + awk for all parsing in shell.
        # awk dynamically finds the Use% column by scanning for ^[0-9]+%$ â€” this handles
        # ZFS dataset names and mount points that contain spaces (e.g. "Windows Server 2016"),
        # which would shift fixed column indices and cause K-block counts to be read as percentages.
        # Type is always 4 columns before Use% in df -T output.
        # Excludes: tmpfs, devtmpfs, squashfs, overlay (pseudo/read-only filesystems).
        # Excludes /mnt/diskN â€” unRAID individual array disk mounts (xfs). These are checked
        # individually and cause false positives; /mnt/user (fuse.shfs) gives the meaningful
        # aggregate array usage and is intentionally included.
        # Excludes /mnt/user0 â€” unRAID direct-access union (duplicate of /mnt/user).
        - name: Get disk usage via awk
          ansible.builtin.shell: |
            df -T | awk -v warn_pct="{{ health_disk_warn_pct }}" '
              NR > 1 {
                pct_col = 0
                for (i = 1; i <= NF; i++) {
                  if ($i ~ /^[0-9]+%$/) { pct_col = i; break }
                }
                if (pct_col > 4) {
                  type = $(pct_col - 4)
                  mnt  = $(pct_col + 1)
                  if (type !~ /^(tmpfs|devtmpfs|squashfs|overlay|none)$/ &&
                      mnt  !~ /^\/mnt\/(disk[0-9]|user0)$/) {
                    pct = $pct_col; gsub(/%/, "", pct)
                    if (pct + 0 > max) max = pct + 0
                    if (pct + 0 >= warn_pct) {
                      mount = ""
                      for (j = pct_col + 1; j <= NF; j++)
                        mount = mount (mount ? " " : "") $j
                      detail = detail (detail ? " | " : "") mount " " $pct_col
                    }
                  }
                }
              }
              END { print max + 0; print detail }
            '
          register: disk_raw
          changed_when: false
          check_mode: false

        - name: Parse disk results
          ansible.builtin.set_fact:
            disk_max_pct: "{{ disk_raw.stdout_lines[0] | default('0') | int }}"
            disk_detail: "{{ disk_raw.stdout_lines[1] | default('') }}"

        - name: Record disk space result
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{
                host_health_issues + [{
                  'check_name': 'disk_space',
                  'status': (
                    'critical' if disk_max_pct | int >= health_disk_crit_pct
                    else ('warning' if disk_max_pct | int >= health_disk_warn_pct else 'ok')
                  ),
                  'value': (disk_max_pct | string + '%') if disk_max_pct | int > 0 else 'ok',
                  'detail': disk_detail
                }]
              }}

      rescue:
        - name: Record disk check error
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{ host_health_issues + [{'check_name': 'disk_space', 'status': 'critical', 'value': 'check_error', 'detail': 'disk check task failed'}] }}

    # â”€â”€ CHECK 10: Memory pressure â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - name: Check memory pressure
      block:
        - name: Calculate memory usage percent
          ansible.builtin.set_fact:
            mem_used_pct: >-
              {{
                ((ansible_memory_mb.nocache.used | default(ansible_memory_mb.real.used)) /
                ansible_memory_mb.real.total * 100) | round(1)
              }}

        - name: Record memory result
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{
                host_health_issues + [{
                  'check_name': 'memory',
                  'status': 'warning' if mem_used_pct | float >= health_mem_warn_pct else 'ok',
                  'value': mem_used_pct | string + '%',
                  'detail': (
                    mem_used_pct | string + '% used of ' + ansible_memory_mb.real.total | string + 'MB'
                    if mem_used_pct | float >= health_mem_warn_pct else ''
                  )
                }]
              }}

      rescue:
        - name: Record memory check error
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{ host_health_issues + [{'check_name': 'memory', 'status': 'critical', 'value': 'check_error', 'detail': 'memory check task failed'}] }}

    # â”€â”€ CHECK 11: CPU load average â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - name: Check CPU load
      block:
        - name: Read 5-minute load average
          ansible.builtin.shell: awk '{print $2}' /proc/loadavg
          register: load_raw
          changed_when: false
          check_mode: false

        - name: Evaluate load against threshold
          ansible.builtin.set_fact:
            load_5m: "{{ load_raw.stdout | float }}"
            load_threshold: "{{ (ansible_processor_vcpus | int * health_cpu_load_multiplier) | round(2) }}"

        - name: Record CPU load result
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{
                host_health_issues + [{
                  'check_name': 'cpu_load',
                  'status': 'warning' if load_5m | float > load_threshold | float else 'ok',
                  'value': 'load: ' + load_5m | string + ' / ' + ansible_processor_vcpus | string + ' vCPUs',
                  'detail': (
                    '5m avg ' + load_5m | string + ' exceeds threshold ' + load_threshold | string
                    if load_5m | float > load_threshold | float else ''
                  )
                }]
              }}

      rescue:
        - name: Record CPU load check error
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{ host_health_issues + [{'check_name': 'cpu_load', 'status': 'critical', 'value': 'check_error', 'detail': 'cpu check task failed'}] }}

    # â”€â”€ CHECK 12: Journal errors â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - name: Check journal errors
      block:
        - name: Count unique journal errors since last check
          ansible.builtin.shell: >
            journalctl -p err
            --since "{{ hostvars['localhost']['last_check'] | replace('T', ' ') | replace('Z', '') }}"
            --no-pager -q 2>/dev/null | sort -u | wc -l
          register: journal_raw
          changed_when: false
          failed_when: false
          check_mode: false

        - name: Record journal error result
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{
                host_health_issues + [{
                  'check_name': 'journal_errors',
                  'status': 'warning' if journal_raw.stdout | int >= health_journal_errors_max else 'ok',
                  'value': journal_raw.stdout | string + ' errors',
                  'detail': (
                    journal_raw.stdout | string + ' journal errors since last check'
                    if journal_raw.stdout | int >= health_journal_errors_max else ''
                  )
                }]
              }}

      rescue:
        - name: Record journal check error
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{ host_health_issues + [{'check_name': 'journal_errors', 'status': 'critical', 'value': 'check_error', 'detail': 'journal check task failed'}] }}

    # â”€â”€ CHECK 13: OOM kills â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - name: Check OOM kills
      block:
        - name: Count OOM kill events since last check
          ansible.builtin.shell: >
            journalctl -k
            --since "{{ hostvars['localhost']['last_check'] | replace('T', ' ') | replace('Z', '') }}"
            --no-pager -q 2>/dev/null | grep -c "Out of memory" || true
          register: oom_count_raw
          changed_when: false
          failed_when: false
          check_mode: false

        - name: Get killed process names
          ansible.builtin.shell: >
            journalctl -k
            --since "{{ hostvars['localhost']['last_check'] | replace('T', ' ') | replace('Z', '') }}"
            --no-pager -q 2>/dev/null | grep "Killed process" | awk '{print $NF}' | sort -u | head -5 || true
          register: oom_procs_raw
          changed_when: false
          failed_when: false
          check_mode: false
          when: oom_count_raw.stdout | int >= health_oom_kills_max

        - name: Record OOM kill result
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{
                host_health_issues + [{
                  'check_name': 'oom_kills',
                  'status': 'critical' if oom_count_raw.stdout | int >= health_oom_kills_max else 'ok',
                  'value': oom_count_raw.stdout | string + ' kills',
                  'detail': (
                    oom_count_raw.stdout | string + ' OOM kills â€” '
                    + ('processes: ' + oom_procs_raw.stdout_lines | join(', ')
                       if (oom_procs_raw is defined and oom_procs_raw.stdout_lines | default([]) | length > 0)
                       else 'process names unavailable')
                    if oom_count_raw.stdout | int >= health_oom_kills_max else ''
                  )
                }]
              }}

      rescue:
        - name: Record OOM check error
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{ host_health_issues + [{'check_name': 'oom_kills', 'status': 'critical', 'value': 'check_error', 'detail': 'oom check task failed'}] }}

    # â”€â”€ CHECK 14: Docker health â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - name: Check Docker health
      when: inventory_hostname in (groups['docker_stacks'] | default([]) + groups['docker_run'] | default([]))
      block:
        - name: Find stopped containers that should be running
          ansible.builtin.shell: |
            docker ps -a --filter "status=exited" --format "{% raw %}{{.Names}}{% endraw %}" | while read name; do
              policy=$(docker inspect --format "{% raw %}{{.HostConfig.RestartPolicy.Name}}{% endraw %}" "$name" 2>/dev/null)
              if [ "$policy" = "always" ] || [ "$policy" = "unless-stopped" ]; then
                echo "$name"
              fi
            done
          register: stopped_raw
          changed_when: false
          failed_when: false
          check_mode: false

        - name: Find unhealthy containers
          ansible.builtin.shell: >
            docker ps --filter "health=unhealthy" --format "{% raw %}{{.Names}}{% endraw %}" 2>/dev/null || true
          register: unhealthy_raw
          changed_when: false
          failed_when: false
          check_mode: false

        - name: Record Docker health result
          ansible.builtin.set_fact:
            docker_stopped: "{{ stopped_raw.stdout_lines | default([]) }}"
            docker_unhealthy: "{{ unhealthy_raw.stdout_lines | default([]) }}"

        - name: Build Docker result
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{
                host_health_issues + [{
                  'check_name': 'docker_health',
                  'status': 'critical' if (docker_stopped | length > 0 or docker_unhealthy | length > 0) else 'ok',
                  'value': (
                    docker_stopped | length | string + ' stopped, '
                    + docker_unhealthy | length | string + ' unhealthy'
                    if (docker_stopped | length > 0 or docker_unhealthy | length > 0) else 'ok'
                  ),
                  'detail': (
                    (docker_stopped | length | string + ' stopped: ' + docker_stopped[:10] | join(', ')
                     if docker_stopped | length > 0 else '')
                    + (' | ' if docker_stopped | length > 0 and docker_unhealthy | length > 0 else '')
                    + (docker_unhealthy | length | string + ' unhealthy: ' + docker_unhealthy[:10] | join(', ')
                       if docker_unhealthy | length > 0 else '')
                  )
                }]
              }}

      rescue:
        - name: Record Docker check error
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{ host_health_issues + [{'check_name': 'docker_health', 'status': 'critical', 'value': 'check_error', 'detail': 'docker check task failed'}] }}

    # Hosts not in docker group get an explicit 'skip' entry so the check is still logged
    - name: Record Docker skipped (non-docker host)
      ansible.builtin.set_fact:
        host_health_issues: >-
          {{ host_health_issues + [{'check_name': 'docker_health', 'status': 'ok', 'value': 'skipped', 'detail': 'not a docker host'}] }}
      when: inventory_hostname not in (groups['docker_stacks'] | default([]) + groups['docker_run'] | default([]))

    # â”€â”€ CHECK 15: SMART disk health â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - name: Check SMART disk health
      block:
        - name: Ensure smartmontools is installed
          become: true
          ansible.builtin.apt:
            name: smartmontools
            state: present
          when: >-
            inventory_hostname in groups['ubuntu'] | default([]) or
            inventory_hostname in groups['pve'] | default([]) or
            inventory_hostname in groups['pbs'] | default([])
          failed_when: false

        - name: Check SMART health on all checkable disks
          become: true
          ansible.builtin.shell: |
            if ! command -v smartctl >/dev/null 2>&1; then echo "no_smartctl"; exit 0; fi
            failed=""
            while IFS= read -r dev; do
              result=$(smartctl -H "$dev" 2>/dev/null)
              if echo "$result" | grep -q "FAILED!"; then
                failed="${failed}$(basename "$dev") "
              fi
            done < <(smartctl --scan 2>/dev/null | awk '{print $1}')
            echo "${failed:-ok}"
          register: smart_raw
          changed_when: false
          failed_when: false
          check_mode: false

        - name: Record SMART result
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{
                host_health_issues + [{
                  'check_name': 'smart_health',
                  'status': (
                    'ok' if smart_raw.stdout | trim in ['ok', 'no_smartctl', '']
                    else 'critical'
                  ),
                  'value': (
                    'all ok' if smart_raw.stdout | trim == 'ok'
                    else ('not installed' if smart_raw.stdout | trim == 'no_smartctl'
                    else ('not checked' if smart_raw.stdout | trim == ''
                    else smart_raw.stdout | trim | split | length | string + ' disk(s) failing'))
                  ),
                  'detail': '' if smart_raw.stdout | trim in ['ok', 'no_smartctl', ''] else smart_raw.stdout | trim
                }]
              }}

      rescue:
        - name: Record SMART check error
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{ host_health_issues + [{'check_name': 'smart_health', 'status': 'critical', 'value': 'check_error', 'detail': 'smart check task failed'}] }}

    # â”€â”€ CHECK 16: Proxmox cluster health (PVE nodes only) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - name: Check Proxmox cluster health
      when: "'pve' in group_names"
      block:
        - name: Get cluster quorum status
          become: true
          ansible.builtin.shell: pvecm status 2>/dev/null
          register: pvecm_raw
          changed_when: false
          failed_when: false
          check_mode: false

        - name: Parse cluster status
          ansible.builtin.set_fact:
            _pvecm_quorate: "{{ pvecm_raw.stdout | regex_search('Quorate:\\s+Yes') is not none }}"
            _pvecm_total: "{{ pvecm_raw.stdout | regex_search('Total votes:\\s+(\\d+)', '\\1') | default(['?'], true) | first }}"
            _pvecm_expected: "{{ pvecm_raw.stdout | regex_search('Expected votes:\\s+(\\d+)', '\\1') | default(['?'], true) | first }}"

        - name: Record cluster health result
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{
                host_health_issues + [{
                  'check_name': 'pve_cluster',
                  'status': 'ok' if _pvecm_quorate else 'critical',
                  'value': _pvecm_total + '/' + _pvecm_expected + ' nodes' + (' quorate' if _pvecm_quorate else ' NOT quorate'),
                  'detail': '' if _pvecm_quorate else pvecm_raw.stdout | truncate(300)
                }]
              }}

      rescue:
        - name: Record cluster check error
          when: "'pve' in group_names"
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{ host_health_issues + [{'check_name': 'pve_cluster', 'status': 'critical', 'value': 'check_error', 'detail': 'cluster check task failed'}] }}

    # â”€â”€ CHECK 17: Ceph health (PVE nodes only) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - name: Check Ceph health
      when: "'pve' in group_names"
      block:
        - name: Get Ceph cluster health
          become: true
          ansible.builtin.shell: |
            if ! command -v ceph >/dev/null 2>&1; then echo "CEPH_NOT_INSTALLED"; exit 0; fi
            ceph health 2>/dev/null || echo "CEPH_ERROR"
          register: ceph_raw
          changed_when: false
          failed_when: false
          check_mode: false

        - name: Record Ceph health result
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{
                host_health_issues + [{
                  'check_name': 'ceph_health',
                  'status': (
                    'ok' if ceph_raw.stdout | trim in ['HEALTH_OK', 'CEPH_NOT_INSTALLED']
                    else ('warning' if 'HEALTH_WARN' in ceph_raw.stdout
                    else 'critical')
                  ),
                  'value': (
                    'not configured' if ceph_raw.stdout | trim == 'CEPH_NOT_INSTALLED'
                    else ceph_raw.stdout | trim | truncate(60)
                  ),
                  'detail': '' if ceph_raw.stdout | trim in ['HEALTH_OK', 'CEPH_NOT_INSTALLED'] else ceph_raw.stdout | trim
                }]
              }}

      rescue:
        - name: Record Ceph check error
          when: "'pve' in group_names"
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{ host_health_issues + [{'check_name': 'ceph_health', 'status': 'critical', 'value': 'check_error', 'detail': 'ceph check task failed'}] }}

    # â”€â”€ CHECK 18: SSL certificate expiry â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - name: Check SSL certificate expiry
      block:
        - name: Check SSL certificate expiry dates
          become: true
          ansible.builtin.shell: |
            certs=$(find /etc/letsencrypt/live -name "cert.pem" 2>/dev/null)
            if [ -z "$certs" ]; then echo "no_certs"; echo ""; exit 0; fi
            days_min=9999
            expiring=""
            while IFS= read -r cert; do
              [ -z "$cert" ] && continue
              domain=$(basename "$(dirname "$cert")")
              expiry_epoch=$(date -d "$(openssl x509 -enddate -noout -in "$cert" 2>/dev/null | cut -d= -f2)" +%s 2>/dev/null)
              [ -z "$expiry_epoch" ] && continue
              days=$(( (expiry_epoch - $(date +%s)) / 86400 ))
              [ "$days" -lt "$days_min" ] && days_min="$days"
              expiring="${expiring}${domain}:${days}d "
            done <<< "$certs"
            echo "$days_min"
            echo "${expiring:-}"
          register: ssl_raw
          changed_when: false
          failed_when: false
          check_mode: false

        - name: Parse SSL cert result
          ansible.builtin.set_fact:
            _ssl_no_certs: "{{ ssl_raw.stdout_lines[0] | default('no_certs') == 'no_certs' }}"
            _ssl_days: "{{ ssl_raw.stdout_lines[0] | default('9999') | int }}"
            _ssl_detail: "{{ ssl_raw.stdout_lines[1] | default('') | trim }}"

        - name: Record SSL cert check
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{
                host_health_issues + [{
                  'check_name': 'ssl_cert',
                  'status': (
                    'ok' if _ssl_no_certs
                    else ('critical' if _ssl_days | int <= health_ssl_crit_days
                    else ('warning' if _ssl_days | int <= health_ssl_warn_days
                    else 'ok'))
                  ),
                  'value': 'no certs' if _ssl_no_certs else _ssl_days | string + ' days',
                  'detail': '' if _ssl_no_certs else _ssl_detail
                }]
              }}

      rescue:
        - name: Record SSL check error
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{ host_health_issues + [{'check_name': 'ssl_cert', 'status': 'critical', 'value': 'check_error', 'detail': 'ssl check task failed'}] }}

    # â”€â”€ CHECK 19: NTP / time sync drift â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - name: Check NTP time sync
      block:
        - name: Check NTP synchronization status
          ansible.builtin.shell: |
            if command -v timedatectl >/dev/null 2>&1; then
              synced=$(timedatectl show --property=NTPSynchronized --value 2>/dev/null || echo "unknown")
              if [ "$synced" = "yes" ]; then
                echo "synced"
              else
                echo "not_synced"
              fi
            elif command -v ntpq >/dev/null 2>&1; then
              offset=$(ntpq -p 2>/dev/null | awk '/^\*/{print $9}')
              if [ -n "$offset" ]; then
                echo "$offset"
              else
                echo "no_peer"
              fi
            else
              echo "no_ntp_tool"
            fi
          register: ntp_raw
          changed_when: false
          failed_when: false
          check_mode: false

        - name: Record NTP sync result
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{
                host_health_issues + [{
                  'check_name': 'ntp_sync',
                  'status': (
                    'ok' if ntp_raw.stdout | trim in ['synced', 'no_ntp_tool']
                    else ('warning' if ntp_raw.stdout | trim == 'not_synced'
                    else ('warning' if ntp_raw.stdout | trim == 'no_peer'
                    else ('warning' if (ntp_raw.stdout | trim | float | abs) > health_ntp_max_offset_ms
                    else 'ok')))
                  ),
                  'value': (
                    'synced' if ntp_raw.stdout | trim == 'synced'
                    else ('no NTP tool' if ntp_raw.stdout | trim == 'no_ntp_tool'
                    else ('not synced' if ntp_raw.stdout | trim == 'not_synced'
                    else ('no peer' if ntp_raw.stdout | trim == 'no_peer'
                    else ntp_raw.stdout | trim + 'ms offset')))
                  ),
                  'detail': '' if ntp_raw.stdout | trim in ['synced', 'no_ntp_tool'] else ntp_raw.stdout | trim
                }]
              }}

      rescue:
        - name: Record NTP check error
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{ host_health_issues + [{'check_name': 'ntp_sync', 'status': 'critical', 'value': 'check_error', 'detail': 'ntp check task failed'}] }}

    # â”€â”€ CHECK 20: DNS resolution â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - name: Check DNS resolution
      block:
        - name: Test DNS resolution
          ansible.builtin.shell: "getent hosts {{ health_dns_hostname }} >/dev/null 2>&1 && echo ok || echo fail"
          register: dns_raw
          changed_when: false
          failed_when: false
          check_mode: false

        - name: Record DNS resolution result
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{
                host_health_issues + [{
                  'check_name': 'dns_resolution',
                  'status': 'ok' if dns_raw.stdout | trim == 'ok' else 'critical',
                  'value': 'ok' if dns_raw.stdout | trim == 'ok' else 'failed',
                  'detail': '' if dns_raw.stdout | trim == 'ok' else 'cannot resolve ' + health_dns_hostname
                }]
              }}

      rescue:
        - name: Record DNS check error
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{ host_health_issues + [{'check_name': 'dns_resolution', 'status': 'critical', 'value': 'check_error', 'detail': 'dns check task failed'}] }}

    # â”€â”€ CHECK 21: unRAID array health (unRAID only) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - name: Check unRAID array health
      when: "'unraid' in group_names"
      block:
        - name: Get unRAID array status
          become: true
          ansible.builtin.shell: |
            if ! command -v mdcmd >/dev/null 2>&1; then echo "no_mdcmd"; exit 0; fi
            state=$(mdcmd status 2>/dev/null | grep '^mdState=' | cut -d= -f2)
            ini=/var/local/emhttp/disks.ini
            # Count DISK_DSBL (present but disabled = real problem).
            dsbl=$(grep -c 'status="DISK_DSBL"' "$ini" 2>/dev/null) || dsbl=0
            # Count DISK_NP_DSBL with non-empty id (configured disk went missing = real problem).
            # DISK_NP_DSBL with empty id is just an unassigned slot (e.g. unused parity2).
            missing=$(awk '/^id=/{id=$0} /^status="DISK_NP_DSBL"/{if(id !~ /^id=""$/) c++} END{print c+0}' "$ini")
            echo "${state:-unknown}|$(( dsbl + missing ))"
          register: unraid_array_raw
          changed_when: false
          failed_when: false
          check_mode: false

        - name: Parse unRAID array status
          ansible.builtin.set_fact:
            _array_state: "{{ unraid_array_raw.stdout.split('|')[0] | default('unknown') }}"
            _array_disabled: "{{ unraid_array_raw.stdout.split('|')[1] | default('0') }}"

        - name: Record unRAID array result
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{
                host_health_issues + [{
                  'check_name': 'unraid_array',
                  'status': (
                    'ok' if _array_state == 'STARTED' and _array_disabled | int == 0
                    else ('ok' if _array_state == 'no_mdcmd'
                    else 'critical')
                  ),
                  'value': (
                    'healthy' if _array_state == 'STARTED' and _array_disabled | int == 0
                    else ('not applicable' if _array_state == 'no_mdcmd'
                    else _array_state + ', ' + _array_disabled | string + ' disabled')
                  ),
                  'detail': (
                    '' if (_array_state == 'STARTED' and _array_disabled | int == 0) or _array_state == 'no_mdcmd'
                    else 'state=' + _array_state + ' disabled=' + _array_disabled | string
                  )
                }]
              }}

      rescue:
        - name: Record unRAID array check error
          when: "'unraid' in group_names"
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{ host_health_issues + [{'check_name': 'unraid_array', 'status': 'critical', 'value': 'check_error', 'detail': 'unraid array check task failed'}] }}

    # â”€â”€ CHECK 22: PBS datastore health (PBS only) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - name: Check PBS datastore health
      when: "'pbs' in group_names"
      block:
        - name: List PBS datastores
          become: true
          ansible.builtin.shell: >
            proxmox-backup-manager datastore list --output-format json 2>/dev/null || echo "[]"
          register: pbs_raw
          changed_when: false
          failed_when: false
          check_mode: false

        - name: Parse PBS datastore results
          ansible.builtin.set_fact:
            _pbs_stores: "{{ pbs_raw.stdout | from_json }}"

        - name: Record PBS datastore result
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{
                host_health_issues + [{
                  'check_name': 'pbs_datastore',
                  'status': 'ok' if _pbs_stores | length > 0 else 'warning',
                  'value': _pbs_stores | length | string + ' datastores',
                  'detail': '' if _pbs_stores | length > 0 else 'no datastores found'
                }]
              }}

      rescue:
        - name: Record PBS datastore check error
          when: "'pbs' in group_names"
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{ host_health_issues + [{'check_name': 'pbs_datastore', 'status': 'critical', 'value': 'check_error', 'detail': 'pbs datastore check task failed'}] }}

    # â”€â”€ CHECK 23: ZFS pool health â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - name: Check ZFS pool health
      block:
        - name: Check ZFS pool health status
          become: true
          ansible.builtin.shell: |
            if ! command -v zpool >/dev/null 2>&1; then echo "no_zpool"; exit 0; fi
            pools=$(zpool list -H -o name,health 2>/dev/null)
            if [ -z "$pools" ]; then echo "no_pools"; exit 0; fi
            degraded=""
            while IFS=$'\t' read -r name health; do
              if [ "$health" != "ONLINE" ]; then
                degraded="${degraded}${name}:${health} "
              fi
            done <<< "$pools"
            if [ -n "$degraded" ]; then
              echo "unhealthy|${degraded}"
            else
              count=$(echo "$pools" | wc -l | tr -d ' ')
              echo "ok|${count}"
            fi
          register: zfs_pool_raw
          changed_when: false
          failed_when: false
          check_mode: false

        - name: Parse ZFS pool result
          ansible.builtin.set_fact:
            _zfs_status: "{{ zfs_pool_raw.stdout.split('|')[0] | default('unknown') }}"
            _zfs_detail: "{{ zfs_pool_raw.stdout.split('|')[1] | default('') | trim }}"

        - name: Record ZFS pool result
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{
                host_health_issues + [{
                  'check_name': 'zfs_pool',
                  'status': (
                    'ok' if _zfs_status in ['ok', 'no_zpool', 'no_pools']
                    else ('warning' if 'DEGRADED' in _zfs_detail
                    else 'critical')
                  ),
                  'value': (
                    'not installed' if _zfs_status == 'no_zpool'
                    else ('no pools' if _zfs_status == 'no_pools'
                    else (_zfs_detail + ' pool(s) healthy' if _zfs_status == 'ok'
                    else _zfs_detail | trim))
                  ),
                  'detail': '' if _zfs_status in ['ok', 'no_zpool', 'no_pools'] else _zfs_detail | trim
                }]
              }}

      rescue:
        - name: Record ZFS pool check error
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{ host_health_issues + [{'check_name': 'zfs_pool', 'status': 'critical', 'value': 'check_error', 'detail': 'zfs pool check task failed'}] }}

    # â”€â”€ CHECK 24: BTRFS filesystem health â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - name: Check BTRFS health
      block:
        - name: Check BTRFS device error counters
          become: true
          ansible.builtin.shell: |
            if ! command -v btrfs >/dev/null 2>&1; then echo "no_btrfs"; exit 0; fi
            mounts=$(findmnt -t btrfs -n -o TARGET 2>/dev/null | sort -u)
            if [ -z "$mounts" ]; then echo "no_filesystems"; exit 0; fi
            errors=""
            count=0
            while IFS= read -r mnt; do
              count=$((count + 1))
              stats=$(btrfs device stats "$mnt" 2>/dev/null) || continue
              errs=$(echo "$stats" | awk '$NF+0 > 0 {print $0}')
              if [ -n "$errs" ]; then
                errors="${errors}${mnt}: $(echo "$errs" | wc -l | tr -d ' ') error counters; "
              fi
            done <<< "$mounts"
            if [ -n "$errors" ]; then
              echo "errors|${errors}"
            else
              echo "ok|${count}"
            fi
          register: btrfs_raw
          changed_when: false
          failed_when: false
          check_mode: false

        - name: Parse BTRFS result
          ansible.builtin.set_fact:
            _btrfs_status: "{{ btrfs_raw.stdout.split('|')[0] | default('unknown') }}"
            _btrfs_detail: "{{ btrfs_raw.stdout.split('|')[1] | default('') | trim }}"

        - name: Record BTRFS health result
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{
                host_health_issues + [{
                  'check_name': 'btrfs_health',
                  'status': (
                    'ok' if _btrfs_status in ['ok', 'no_btrfs', 'no_filesystems']
                    else 'critical'
                  ),
                  'value': (
                    'not installed' if _btrfs_status == 'no_btrfs'
                    else ('no filesystems' if _btrfs_status == 'no_filesystems'
                    else (_btrfs_detail + ' filesystem(s) healthy' if _btrfs_status == 'ok'
                    else 'device errors detected'))
                  ),
                  'detail': '' if _btrfs_status in ['ok', 'no_btrfs', 'no_filesystems'] else _btrfs_detail | trim
                }]
              }}

      rescue:
        - name: Record BTRFS check error
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{ host_health_issues + [{'check_name': 'btrfs_health', 'status': 'critical', 'value': 'check_error', 'detail': 'btrfs health check task failed'}] }}

    # â”€â”€ CHECK 25: Docker container HTTP responsiveness â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - name: Check Docker HTTP health
      when: docker_health_endpoints | default([]) | length > 0
      block:
        - name: Check Docker container HTTP endpoints
          ansible.builtin.uri:
            url: "{{ endpoint.url }}"
            method: GET
            status_code: "{{ endpoint.status_code | default(200) }}"
            timeout: 10
            validate_certs: "{{ endpoint.validate_certs | default(true) }}"
          loop: "{{ docker_health_endpoints }}"
          loop_control:
            loop_var: endpoint
            label: "{{ endpoint.name }}"
          register: http_results
          ignore_errors: true

        - name: Build HTTP health results
          ansible.builtin.set_fact:
            _http_failures: >-
              {{ http_results.results | default([])
                 | selectattr('failed', 'defined')
                 | selectattr('failed')
                 | map(attribute='endpoint')
                 | map(attribute='name')
                 | list }}

        - name: Record Docker HTTP result
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{
                host_health_issues + [{
                  'check_name': 'docker_http',
                  'status': 'critical' if _http_failures | length > 0 else 'ok',
                  'value': (
                    _http_failures | length | string + ' failing'
                    if _http_failures | length > 0
                    else docker_health_endpoints | length | string + ' endpoints ok'
                  ),
                  'detail': _http_failures | join(', ') if _http_failures | length > 0 else ''
                }]
              }}

      rescue:
        - name: Record Docker HTTP check error
          ansible.builtin.set_fact:
            host_health_issues: >-
              {{ host_health_issues + [{'check_name': 'docker_http', 'status': 'critical', 'value': 'check_error', 'detail': 'docker http check task failed'}] }}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PLAY 3 â€” LOCALHOST: AGGREGATE, ALERT, LOG, SAVE STATE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
- name: Check health â€” aggregate and alert
  hosts: localhost
  gather_facts: true
  vars_files:
    - vars/secrets.yaml
    - vars/semaphore_check.yaml
  vars:
    maintenance_name: "Semaphore"
    maintenance_type: "Local"
    maintenance_subtype: "Health Check"
    maintenance_url: "{{ semaphore_ext_url }}"
    maintenance_description: "Scheduled health monitoring checks"
    ssh_hosts: "{{ health_check_groups | map('extract', groups) | map('default', []) | flatten }}"

  tasks:

    - name: Restore Play 1 state
      ansible.builtin.set_fact:
        maintenance_failed: "{{ hostvars['localhost']['maintenance_failed'] | default(false) }}"
        play1_health_results: "{{ hostvars['localhost']['play1_health_results'] | default([]) }}"

    # â”€â”€ CHECK 26: UNREACHABLE HOST ALERTING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - name: Build unreachable host list
      ansible.builtin.set_fact:
        unreachable_hosts: "{{ unreachable_hosts | default([]) + [item] }}"
      loop: "{{ ssh_hosts }}"
      when: not (hostvars[item]['host_reachable'] | default(false))

    - name: Initialize unreachable_hosts if all reachable
      ansible.builtin.set_fact:
        unreachable_hosts: "{{ unreachable_hosts | default([]) }}"

    - name: Send Discord alert for unreachable hosts
      include_tasks: tasks/notify_discord.yaml
      when: unreachable_hosts | length > 0
      vars:
        discord_title: "ðŸ”´ Unreachable Hosts"
        discord_color: "{{ discord_color_failure }}"
        discord_description: "The following hosts did not respond to SSH during the health check."
        discord_author: "{{ controller_fqdn }}"
        discord_fields:
          - name: "Unreachable"
            value: "{{ unreachable_hosts | join(', ') }}"
        discord_footer:
          text: "Health Check"
        discord_timestamp: "{{ now(utc=true).strftime('%Y-%m-%dT%H:%M:%SZ') }}"

    # â”€â”€ PER-HOST DISCORD ALERTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - name: Send Discord alert for hosts with issues
      include_tasks: tasks/notify_discord.yaml
      loop: "{{ ssh_hosts }}"
      loop_control:
        label: "{{ item }}"
      when:
        - hostvars[item]['host_reachable'] | default(false)
        - (hostvars[item]['host_health_issues'] | default([]) | selectattr('status', 'ne', 'ok') | list | length) > 0
      vars:
        discord_title: >-
          {{ 'ðŸ”´' if (hostvars[item]['host_health_issues'] | default([]) | selectattr('status', 'equalto', 'critical') | list | length > 0) else 'âš ï¸' }}
          System Health â€” {{ item }}
        discord_color: >-
          {{ 16711680 if (hostvars[item]['host_health_issues'] | default([]) | selectattr('status', 'equalto', 'critical') | list | length > 0) else 16753920 }}
        discord_author: "{{ item }}"
        discord_fields: >-
          {{
            hostvars[item]['host_health_issues']
            | default([])
            | selectattr('status', 'ne', 'ok')
            | json_query('[].{name: check_name, value: value}')
          }}
        discord_footer:
          text: "Health Check"
        discord_timestamp: "{{ now(utc=true).strftime('%Y-%m-%dT%H:%M:%SZ') }}"

    # â”€â”€ BATCH LOG â€” unified results to DB in a single INSERT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - name: Build unified results â€” Play 1 checks
      ansible.builtin.set_fact:
        _all_results: "{{ play1_health_results | map('combine', {'hostname': controller_fqdn}) | list }}"

    - name: Build unified results â€” unreachable hosts
      ansible.builtin.set_fact:
        _all_results: "{{ _all_results + [{'hostname': item, 'check_name': 'host_reachable', 'status': 'critical', 'value': 'unreachable', 'detail': 'Host did not respond to SSH'}] }}"
      loop: "{{ unreachable_hosts }}"

    - name: Build unified results â€” per-host checks
      ansible.builtin.set_fact:
        _all_results: >-
          {{ _all_results +
             (hostvars[item]['host_health_issues'] | default([])
              | map('combine', {'hostname': item}) | list)
          }}
      loop: "{{ ssh_hosts }}"
      when: hostvars[item]['host_reachable'] | default(false)

    - name: Batch log all health check results to DB
      include_tasks: tasks/log_health_checks_batch.yaml
      when: _all_results | length > 0

    - name: Detect partial failures from check errors
      ansible.builtin.set_fact:
        maintenance_partial: >-
          {{ (_all_results | default([]) | selectattr('value', 'equalto', 'check_error') | list | length > 0)
             and not maintenance_failed }}

    # â”€â”€ FINALIZE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - name: Save health check state to DB
      vars:
        ansible_python_interpreter: "{{ ansible_playbook_python }}"
      become: false
      connection: local
      community.mysql.mysql_query:
        login_host: "{{ logging_db_host }}"
        login_port: "{{ logging_db_port }}"
        login_user: "{{ logging_db_user }}"
        login_password: "{{ logging_db_password }}"
        login_db: "{{ logging_db_name }}"
        query: "INSERT INTO health_check_state (id, last_check) VALUES (1, UTC_TIMESTAMP()) ON DUPLICATE KEY UPDATE last_check = UTC_TIMESTAMP()"
      when: not ansible_check_mode
      no_log: true

    - name: Send Discord alert on maintenance failure
      include_tasks: tasks/notify_discord.yaml
      when: maintenance_failed
      vars:
        discord_name: "{{ maintenance_name }}"
        discord_operation: "Health"
        discord_status: "failed"
        discord_detail: "one or more checks encountered an error"
        discord_color: "{{ discord_color_failure }}"
        discord_url: "{{ maintenance_url }}"
        discord_author: "{{ controller_fqdn }}"

    - name: Log maintenance to MariaDB
      include_tasks: tasks/log_mariadb.yaml
      vars:
        log_table: "maintenance"
        log_application: "{{ maintenance_name }}"
        log_hostname: "{{ controller_fqdn }}"
        log_type: "{{ maintenance_type }}"
        log_subtype: "{{ maintenance_subtype }}"
        log_status: "{{ 'failed' if maintenance_failed else ('partial' if maintenance_partial | default(false) else 'success') }}"

    # â”€â”€ DEAD MAN'S SWITCH â€” Uptime Kuma push heartbeat â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # If this playbook fails to complete (crashes, hangs, scheduler dies), Uptime Kuma
    # will detect the missing heartbeat and alert independently of Discord.
    - name: Send heartbeat to Uptime Kuma
      ansible.builtin.uri:
        url: "{{ uptime_kuma_push_url }}"
        method: GET
        status_code: 200
        timeout: 10
      when:
        - not ansible_check_mode
        - uptime_kuma_push_url is defined
        - not maintenance_failed
      failed_when: false
