---
# Bootstrap an Ubuntu VM with security hardening, base packages, and optionally Docker + VIPs.
# Extracted from build_ubuntu.yaml Play 2. Caller must set become: true.
#
# Expects:
#   vm_user   — user account for group membership
# Optional:
#   _vm              — dict from vm_definitions; enables NFS mounts and UFW rules
#                      when _vm.nfs_mounts or _vm.ufw_rules are defined
#   _install_docker  — install Docker + keepalived (default: true)

- name: Wait for cloud-init to finish
  ansible.builtin.command: cloud-init status --wait
  register: _cloud_init
  changed_when: false
  failed_when: "'status: done' not in _cloud_init.stdout"

- name: Wait for apt lock to be released
  ansible.builtin.shell: while fuser /var/lib/dpkg/lock-frontend >/dev/null 2>&1; do sleep 5; done
  changed_when: false

- name: Update and upgrade apt packages
  ansible.builtin.apt:
    update_cache: true
    upgrade: dist

- name: Install base packages
  ansible.builtin.apt:
    name:
      - python3-pip
      - nfs-common
      - curl
      - htop
      - pigz
      - unattended-upgrades
      - qemu-guest-agent
    state: present

- name: Enable qemu-guest-agent service
  ansible.builtin.systemd:
    name: qemu-guest-agent
    enabled: true
    state: started

- name: Add user to sudo group
  ansible.builtin.user:
    name: "{{ vm_user }}"
    groups: sudo
    append: true

- name: Configure Docker and VIPs
  when: _install_docker | default(true) | bool
  block:
    - name: Install Docker packages
      ansible.builtin.apt:
        name:
          - docker.io
          - docker-compose-v2
          - python3-docker
        state: present

    - name: Enable Docker service
      ansible.builtin.systemd:
        name: docker
        enabled: true
        state: started

    - name: Add user to docker group
      ansible.builtin.user:
        name: "{{ vm_user }}"
        groups: docker
        append: true

    - name: Configure keepalived (VIP management)
      when:
        - host_roles is defined
        - inventory_hostname in host_roles
        - host_roles[inventory_hostname] in (docker_vips | default({}))
      block:
        - name: Install keepalived
          ansible.builtin.apt:
            name: keepalived
            state: present

        - name: Template keepalived config
          ansible.builtin.template:
            src: templates/keepalived-docker.conf.j2
            dest: /etc/keepalived/keepalived.conf
            owner: root
            group: root
            mode: "0640"
          register: _keepalived_config

        - name: Enable and start keepalived
          ansible.builtin.service:
            name: keepalived
            state: started
            enabled: true

        - name: Restart keepalived if config changed
          ansible.builtin.service:
            name: keepalived
            state: restarted
          when: _keepalived_config.changed | default(false)

- name: Harden SSH and configure passwordless sudo
  include_tasks: tasks/ssh_hardening.yaml
  vars:
    _ssh_user: "{{ vm_user }}"

- name: Deploy ansible SSH private key
  when: deploy_ssh_key | default(false) | bool
  block:
    - name: Ensure .ssh directory exists for ansible user
      ansible.builtin.file:
        path: "/home/{{ vm_user }}/.ssh"
        state: directory
        owner: "{{ vm_user }}"
        group: "{{ vm_user }}"
        mode: "0700"

    - name: Write SSH private key
      ansible.builtin.copy:
        content: "{{ ansible_user_ssh_private_key }}"
        dest: "/home/{{ vm_user }}/.ssh/id_ed25519"
        owner: "{{ vm_user }}"
        group: "{{ vm_user }}"
        mode: "0600"
      no_log: true

    - name: Write SSH client config (accept new host keys, no interactive prompts)
      ansible.builtin.copy:
        content: |
          Host *
            StrictHostKeyChecking accept-new
            IdentityFile ~/.ssh/id_ed25519
        dest: "/home/{{ vm_user }}/.ssh/config"
        owner: "{{ vm_user }}"
        group: "{{ vm_user }}"
        mode: "0600"

- name: Enable UFW with default deny incoming
  community.general.ufw:
    state: enabled
    default: deny
    direction: incoming

- name: Allow SSH through UFW
  community.general.ufw:
    rule: allow
    port: "{{ ansible_port | default('22') }}"
    proto: tcp

- name: Apply additional UFW rules
  community.general.ufw:
    rule: "{{ item.rule | default('allow') }}"
    port: "{{ item.port }}"
    proto: "{{ item.proto | default('tcp') }}"
    src: "{{ item.src | default(omit) }}"
    comment: "{{ item.comment | default(omit) }}"
  loop: "{{ _vm.ufw_rules }}"
  loop_control:
    label: "{{ item.port }}/{{ item.proto | default('tcp') }}"
  when: _vm.ufw_rules is defined

- name: Install NFS server
  ansible.builtin.apt:
    name: nfs-kernel-server
    state: present
  when: _vm.nfs_exports is defined

- name: Configure NFS exports
  ansible.builtin.lineinfile:
    path: /etc/exports
    line: "{{ item.path }} {{ item.clients }}"
    regexp: "^{{ item.path | regex_escape }}\\s"
    create: true
    mode: "0644"
  loop: "{{ _vm.nfs_exports }}"
  loop_control:
    label: "{{ item.path }}"
  register: _nfs_exports
  when: _vm.nfs_exports is defined

- name: Reload NFS exports
  ansible.builtin.command: exportfs -ra
  changed_when: true
  when:
    - _vm.nfs_exports is defined
    - _nfs_exports.changed

- name: Verify NFS server reachable — {{ item.src.split(':')[0] }}
  ansible.builtin.wait_for:
    host: "{{ item.src.split(':')[0] }}"
    port: 2049
    timeout: 10
    state: started
    msg: >-
      NFS server {{ item.src.split(':')[0] }} port 2049 unreachable after 10s.
      Verify the NFS server is running (systemctl status nfs-kernel-server)
      and the IP is correct in vault.
  loop: "{{ _vm.nfs_mounts }}"
  loop_control:
    label: "{{ item.src }}"
  when: _vm.nfs_mounts is defined

- name: Configure NFS mounts
  ansible.posix.mount:
    path: "{{ item.path }}"
    src: "{{ item.src }}"
    fstype: nfs
    opts: "{{ item.opts | default('defaults,_netdev') }}"
    state: mounted
  loop: "{{ _vm.nfs_mounts }}"
  loop_control:
    label: "{{ item.path }}"
  when: _vm.nfs_mounts is defined

- name: Configure loopback IP aliases (production host IPs)
  ansible.builtin.template:
    src: templates/netplan-loopback-aliases.j2
    dest: /etc/netplan/60-loopback-aliases.yaml
    mode: '0600'
  when: _vm.ip_aliases is defined
  register: _netplan_aliases

- name: Apply netplan loopback aliases
  ansible.builtin.command: netplan apply
  changed_when: true
  when:
    - _vm.ip_aliases is defined
    - _netplan_aliases.changed

- name: Install ceph-common
  ansible.builtin.apt:
    name: ceph-common
    state: present
  when: _vm.cephfs_host_dir is defined

- name: Write CephFS client keyring (INI format — for ceph CLI tools)
  ansible.builtin.copy:
    content: |
      [client.{{ cephfs_client_name }}]
          key = {{ vault_ceph_vm_appdata_key }}
    dest: "{{ cephfs_keyring_path }}"
    owner: root
    group: root
    mode: "0600"
  when: _vm.cephfs_host_dir is defined

- name: Write CephFS mount secret (raw key — for kernel secretfile= option)
  ansible.builtin.copy:
    content: "{{ vault_ceph_vm_appdata_key }}"
    dest: "{{ cephfs_keyring_path | regex_replace('\\.keyring$', '.secret') }}"
    owner: root
    group: root
    mode: "0600"
  when: _vm.cephfs_host_dir is defined

- name: Write minimal ceph.conf (suppresses DNS SRV fallback warning)
  ansible.builtin.copy:
    content: |
      [global]
      mon_host = {{ vault_ceph_mons }}
    dest: /etc/ceph/ceph.conf
    owner: root
    group: root
    mode: "0644"
  when: _vm.cephfs_host_dir is defined

- name: Assert test VM does not mount production CephFS directory
  ansible.builtin.assert:
    that:
      - _vm.cephfs_host_dir not in cephfs_production_dirs
    fail_msg: >-
      Test VM '{{ _vm.vm_name }}' has cephfs_host_dir='{{ _vm.cephfs_host_dir }}'
      which is a production directory. Test VMs must use a test-only CephFS path.
  when:
    - _vm.cephfs_host_dir is defined
    - _vm.vm_vlan_tag is defined

- name: Ensure CephFS subdirectory exists
  ansible.builtin.shell: |
    TEMP_MNT=$(mktemp -d)
    mount -t ceph {{ vault_ceph_mons }}:/ "$TEMP_MNT" \
      -o name={{ cephfs_client_name }},secretfile={{ cephfs_keyring_path | replace('.keyring', '.secret') }}
    mkdir -p "$TEMP_MNT/{{ _vm.cephfs_host_dir }}"
    umount "$TEMP_MNT"
    rmdir "$TEMP_MNT"
  changed_when: false
  when: _vm.cephfs_host_dir is defined

- name: Mount CephFS at /opt
  ansible.posix.mount:
    path: /opt
    src: "{{ vault_ceph_mons }}:/{{ _vm.cephfs_host_dir }}"
    fstype: ceph
    opts: "name={{ cephfs_client_name }},secretfile={{ cephfs_keyring_path | regex_replace('\\.keyring$', '.secret') }},_netdev,x-systemd.requires=network-online.target"
    state: mounted
  when: _vm.cephfs_host_dir is defined

- name: Mount additional CephFS directories
  ansible.posix.mount:
    path: "{{ item.mount_path }}"
    src: "{{ vault_ceph_mons }}:/{{ item.cephfs_dir }}"
    fstype: ceph
    opts: "name={{ cephfs_client_name }},secretfile={{ cephfs_keyring_path | regex_replace('\\.keyring$', '.secret') }},_netdev,x-systemd.requires=network-online.target"
    state: mounted
  loop: "{{ _vm.cephfs_extra_mounts }}"
  loop_control:
    label: "{{ item.mount_path }}"
  when: _vm.cephfs_extra_mounts is defined

