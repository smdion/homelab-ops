---
# Test the CephFS migration flow using a disposable VM loaded with real backup data.
# Provisions the dedicated cephfs-migrate-test VM (VMID: vm_test_slot_base + vm_test_slot_count, production VLAN), restores
# backup archives from source_host to its local /opt, then runs the full CephFS migration
# inline and verifies the result. Use this to validate migrate_appdata_to_cephfs.yaml
# before running it on production.
#
# Required extra vars:
#   source_host  — FQDN of source host in stack_assignments (e.g. odyssey's hostname)
#
# Optional extra vars:
#   keep_vm=yes  — skip VM stop after test (for post-test inspection; default: VM is stopped)
#
# Prerequisites (manual, on PVE cluster):
#   1. CephFS operational (see migrate_appdata_to_cephfs.yaml prerequisites 1–3)
#   2. Backup archives exist for source_host on the Semaphore controller
#   (Play 1 automatically creates /cephfs-migrate-test on CephFS root if missing)

# ═══════════════════════════════════════════════════════════════════
# Play 1 — Validate, find backups, provision test VM
# ═══════════════════════════════════════════════════════════════════
- name: Prepare CephFS migration test
  hosts: localhost
  gather_facts: true
  gather_subset: ['!all', 'date_time']
  vars_files:
    - vars/secrets.yaml
    - vars/proxmox.yaml
    - vars/docker_stacks.yaml
    - vars/vm_definitions.yaml
    - vars/semaphore_check.yaml

  pre_tasks:
    - name: Assert source_host is defined and in stack_assignments
      ansible.builtin.assert:
        that:
          - source_host is defined
          - source_host in stack_assignments
        fail_msg: >-
          source_host '{{ source_host | default('undefined') }}' not found in stack_assignments.
          Valid hosts: {{ stack_assignments.keys() | list | join(', ') }}

    - name: Assert MariaDB logging database is reachable
      include_tasks: tasks/assert_db_connectivity.yaml

    - name: Log playbook run context to MariaDB
      include_tasks: tasks/log_run_context.yaml
      vars:
        log_playbook: "test_migrate_cephfs.yaml"
        log_hostname: "{{ controller_fqdn }}"
        log_run_vars: "{{ {'source_host': source_host} | to_json | to_json }}"

  tasks:
    - name: Resolve test VM and stack configuration
      ansible.builtin.set_fact:
        _vm: "{{ vm_definitions['cephfs-migrate-test'] }}"
        _stacks: "{{ stack_assignments[source_host] }}"

    # ── Ensure CephFS test directory exists ───────────────────────
    - name: Add PVE host to in-memory inventory
      ansible.builtin.add_host:
        name: pve_builder
        ansible_host: "{{ pve_api_host }}"
        ansible_user: ansible

    - name: Ensure /cephfs-migrate-test directory exists on CephFS root
      ansible.builtin.shell: |
        set -e
        MOUNT_DIR=$(mktemp -d)
        ADMIN_KEY=$(ceph auth print-key client.admin)
        mount -t ceph {{ vault_ceph_mons }}:/ "$MOUNT_DIR" \
          -o "name=admin,secret=${ADMIN_KEY}"
        if [ -d "$MOUNT_DIR/cephfs-migrate-test" ]; then
          echo "exists"
        else
          mkdir "$MOUNT_DIR/cephfs-migrate-test"
          echo "created"
        fi
        umount "$MOUNT_DIR"
        rmdir "$MOUNT_DIR"
      args:
        executable: /bin/bash
      delegate_to: pve_builder
      become: true
      register: _cephfs_dir_result
      changed_when: "'created' in _cephfs_dir_result.stdout"
      no_log: "{{ not (debug_no_log | default(false) | bool) and (ansible_verbosity | default(0) | int < 3) }}"

    # ── Find backup archives ───────────────────────────────────────
    - name: Find per-stack backup archives for source host
      ansible.builtin.shell: >
        ls -t {{ backup_base_dir }}/{{ source_host }}/backup_{{ item }}_*.tar.gz 2>/dev/null | head -1
      loop: "{{ _stacks }}"
      register: _per_stack_archives
      become: false
      changed_when: false
      check_mode: false

    - name: Set per-stack archive list
      ansible.builtin.set_fact:
        _archive_files: "{{ _per_stack_archives.results | selectattr('stdout', 'ne', '') | map(attribute='stdout') | list }}"

    - name: Fall back to monolithic archive
      ansible.builtin.shell: >
        ls -t {{ backup_base_dir }}/{{ source_host }}/backup_*.tar.gz 2>/dev/null | head -1
      register: _monolithic_archive
      become: false
      changed_when: false
      check_mode: false
      when: _archive_files | length == 0

    - name: Use monolithic archive as fallback
      ansible.builtin.set_fact:
        _archive_files: "{{ [_monolithic_archive.stdout] }}"
      when:
        - _archive_files | length == 0
        - _monolithic_archive.stdout | default('') | length > 0

    - name: Assert backup archives exist
      ansible.builtin.assert:
        that: _archive_files | length > 0
        fail_msg: "No backup archives found for {{ source_host }}"

    - name: Verify archive integrity
      ansible.builtin.shell: gunzip -t "{{ item }}"
      loop: "{{ _archive_files }}"
      become: false
      changed_when: false
      check_mode: false

    # ── Check/provision test VM ────────────────────────────────────
    - name: Check if VM exists in cluster
      ansible.builtin.uri:
        url: "https://{{ pve_api_host }}:8006/api2/json/cluster/resources?type=vm"
        method: GET
        headers:
          Authorization: "PVEAPIToken={{ pve_api_user }}!{{ pve_api_token_id }}={{ pve_api_token_secret }}"
        validate_certs: false
      register: _cluster_vms
      no_log: "{{ not (debug_no_log | default(false) | bool) and (ansible_verbosity | default(0) | int < 3) }}"

    - name: Set VM existence and node facts
      ansible.builtin.set_fact:
        _vm_exists: "{{ _cluster_vms.json.data | selectattr('vmid', 'equalto', _vm.vm_id | int) | list | length > 0 }}"
        _vm_actual_node: >-
          {{ (_cluster_vms.json.data | selectattr('vmid', 'equalto', _vm.vm_id | int) | list | first).node
             if (_cluster_vms.json.data | selectattr('vmid', 'equalto', _vm.vm_id | int) | list | length > 0)
             else _vm.pve_target_node }}
        _vm_cluster_status: >-
          {{ (_cluster_vms.json.data | selectattr('vmid', 'equalto', _vm.vm_id | int) | list | first).status
             if (_cluster_vms.json.data | selectattr('vmid', 'equalto', _vm.vm_id | int) | list | length > 0)
             else 'unknown' }}

    - name: Provision VM on Proxmox
      include_tasks: tasks/provision_vm.yaml
      vars:
        _provision_target_group: migrate_test_target
      when: not _vm_exists

    - name: Add existing VM to inventory
      ansible.builtin.add_host:
        name: "{{ _vm.vm_hostname }}"
        ansible_host: "{{ _vm.vm_ip }}"
        ansible_user: "{{ vm_user }}"
        groups: migrate_test_target
        _needs_bootstrap: false
      when: _vm_exists

    - name: Start existing VM if stopped
      ansible.builtin.uri:
        url: "https://{{ pve_api_host }}:8006/api2/json/nodes/{{ _vm_actual_node }}/qemu/{{ _vm.vm_id }}/status/start"
        method: POST
        headers:
          Authorization: "PVEAPIToken={{ pve_api_user }}!{{ pve_api_token_id }}={{ pve_api_token_secret }}"
        validate_certs: false
        status_code: [200, 500]
      no_log: "{{ not (debug_no_log | default(false) | bool) and (ansible_verbosity | default(0) | int < 3) }}"
      when:
        - _vm_exists
        - _vm_cluster_status == 'stopped'

    - name: Wait for SSH on existing VM
      ansible.builtin.wait_for:
        host: "{{ _vm.vm_ip }}"
        port: 22
        delay: 10
        timeout: 300
      when:
        - _vm_exists
        - _vm_cluster_status == 'stopped'

# ═══════════════════════════════════════════════════════════════════
# Play 2 — Bootstrap (Docker install; NO CephFS mount)
# ═══════════════════════════════════════════════════════════════════
- name: Bootstrap test VM
  hosts: migrate_test_target
  become: true
  gather_facts: true
  vars_files:
    - vars/secrets.yaml
    - vars/vm_definitions.yaml

  tasks:
    - name: Check if Docker is installed
      ansible.builtin.command: docker --version
      register: _docker_check
      failed_when: false
      changed_when: false
      become: false

    - name: Bootstrap VM (without CephFS — /opt stays local for migration test)
      include_tasks: tasks/bootstrap_vm.yaml
      vars:
        # Strip cephfs_host_dir so bootstrap_vm.yaml does NOT mount CephFS at /opt.
        # /opt must start as local disk for the migrate flow to work correctly.
        _vm: "{{ hostvars['localhost']._vm | dict2items | rejectattr('key', 'equalto', 'cephfs_host_dir') | items2dict }}"
      when: hostvars[inventory_hostname]._needs_bootstrap | default(false) or _docker_check.rc != 0

# ═══════════════════════════════════════════════════════════════════
# Play 3 — Restore backup data, run CephFS migration, verify
# ═══════════════════════════════════════════════════════════════════
- name: Restore data, migrate to CephFS, and verify
  hosts: migrate_test_target
  become: true
  gather_facts: true
  gather_subset: ['!all', 'date_time']
  vars_files:
    - vars/secrets.yaml
    - vars/vm_definitions.yaml
    - vars/semaphore_check.yaml

  tasks:
    - name: Initialize test state
      ansible.builtin.set_fact:
        _test_failed: false
        _test_detail: ""

    - block:
        # ─── Restore backup archives to local /opt ──────────────────
        - name: Restore appdata from each archive
          include_tasks: tasks/restore_appdata.yaml
          loop: "{{ hostvars['localhost']._archive_files }}"
          loop_control:
            loop_var: _current_archive
          vars:
            _restore_archive_path: "{{ _current_archive }}"
            _restore_mode: inplace
            backup_tmp_dir: "/tmp"

        - name: Check /opt/stacks exists after restore
          ansible.builtin.stat:
            path: /opt/stacks
          register: _opt_stacks_pre

        - name: Assert /opt/stacks restored
          ansible.builtin.assert:
            that: _opt_stacks_pre.stat.exists and _opt_stacks_pre.stat.isdir
            fail_msg: "/opt/stacks missing after restore — archive may not contain stacks directory"

        # ─── Pre-flight check ────────────────────────────────────────
        - name: Check /opt is NOT already a CephFS mount
          ansible.builtin.command: findmnt -t ceph /opt
          register: _cephfs_pre_check
          changed_when: false
          failed_when: false

        - name: Assert /opt is not already CephFS-mounted
          ansible.builtin.fail:
            msg: "/opt is already mounted as CephFS — test VM is in unexpected state"
          when: _cephfs_pre_check.rc == 0

        # ─── Install ceph-common and write keyring ───────────────────
        - name: Install ceph-common
          ansible.builtin.apt:
            name: ceph-common
            state: present

        - name: Write CephFS client keyring (INI format — for ceph CLI tools)
          ansible.builtin.copy:
            content: |
              [client.{{ cephfs_client_name }}]
                  key = {{ vault_ceph_vm_appdata_key }}
            dest: "{{ cephfs_keyring_path }}"
            owner: root
            group: root
            mode: "0600"

        - name: Write CephFS mount secret (raw key — for kernel secretfile= option)
          ansible.builtin.copy:
            content: "{{ vault_ceph_vm_appdata_key }}"
            dest: "{{ cephfs_keyring_path | regex_replace('\\.keyring$', '.secret') }}"
            owner: root
            group: root
            mode: "0600"

        - name: Write minimal ceph.conf (suppresses DNS SRV fallback warning)
          ansible.builtin.copy:
            content: |
              [global]
              mon_host = {{ vault_ceph_mons }}
            dest: /etc/ceph/ceph.conf
            owner: root
            group: root
            mode: "0644"

        # ─── Mount CephFS at staging, rsync, remount /opt ────────────
        - name: Create staging mount directory
          ansible.builtin.file:
            path: /mnt/cephfs_migrate
            state: directory
            mode: "0755"

        - name: Mount CephFS at /mnt/cephfs_migrate (staging)
          ansible.posix.mount:
            path: /mnt/cephfs_migrate
            src: "{{ vault_ceph_mons }}:/{{ hostvars['localhost']._vm.cephfs_host_dir }}"
            fstype: ceph
            opts: "name={{ cephfs_client_name }},secretfile={{ cephfs_keyring_path | regex_replace('\\.keyring$', '.secret') }},_netdev,x-systemd.requires=network-online.target"
            state: mounted

        - name: Sync /opt to CephFS staging (this may take several minutes)
          ansible.builtin.command: rsync -av --delete /opt/ /mnt/cephfs_migrate/
          changed_when: true
          timeout: 3600

        - name: Check stacks directory exists on CephFS after rsync
          ansible.builtin.stat:
            path: /mnt/cephfs_migrate/stacks
          register: _cephfs_stacks_dir

        - name: Assert rsync spot-check passed
          ansible.builtin.assert:
            that: _cephfs_stacks_dir.stat.exists and _cephfs_stacks_dir.stat.isdir
            fail_msg: "/mnt/cephfs_migrate/stacks not found after rsync — aborting before remount"

        - name: Remove staging mount from fstab and unmount
          ansible.posix.mount:
            path: /mnt/cephfs_migrate
            state: absent

        - name: Mount CephFS at /opt
          ansible.posix.mount:
            path: /opt
            src: "{{ vault_ceph_mons }}:/{{ hostvars['localhost']._vm.cephfs_host_dir }}"
            fstype: ceph
            opts: "name={{ cephfs_client_name }},secretfile={{ cephfs_keyring_path | regex_replace('\\.keyring$', '.secret') }},_netdev,x-systemd.requires=network-online.target"
            state: mounted

        # ─── Verify CephFS mount ─────────────────────────────────────
        - name: Verify /opt is mounted as CephFS
          ansible.builtin.command: findmnt -t ceph /opt
          register: _findmnt_post
          changed_when: false

        - name: Show mount info
          ansible.builtin.debug:
            msg: "{{ _findmnt_post.stdout_lines }}"

        - name: Verify mount source contains expected host dir
          ansible.builtin.assert:
            that: hostvars['localhost']._vm.cephfs_host_dir in _findmnt_post.stdout
            fail_msg: >-
              /opt is mounted as ceph but source does not contain
              '{{ hostvars['localhost']._vm.cephfs_host_dir }}' — check mount config

        - name: Write CephFS marker file
          ansible.builtin.copy:
            content: "cephfs-migrate-test {{ ansible_date_time.iso8601 }}\n"
            dest: /opt/.cephfs-verify
            mode: "0644"

        - name: Read marker file back
          ansible.builtin.slurp:
            src: /opt/.cephfs-verify
          register: _marker

        - name: Assert marker file is readable
          ansible.builtin.assert:
            that: "'cephfs-migrate-test' in (_marker.content | b64decode)"
            fail_msg: "Marker file not readable — CephFS read/write may be broken"

        - name: Verify /opt/stacks exists on CephFS
          ansible.builtin.stat:
            path: /opt/stacks
          register: _cephfs_final_stacks

        - name: Record test detail
          ansible.builtin.set_fact:
            _test_detail: >-
              {{ source_host }} data restored to local /opt, migrated to
              CephFS:/{{ hostvars['localhost']._vm.cephfs_host_dir }},
              marker verified —
              {{ '/opt/stacks present' if _cephfs_final_stacks.stat.exists else '/opt/stacks missing' }}

      rescue:
        - name: Set test failed flag
          ansible.builtin.set_fact:
            _test_failed: true
            _test_detail: "{{ ansible_failed_result.msg | default('check Semaphore logs') }}"

        - name: Emergency — unmount CephFS from /opt if mounted
          ansible.posix.mount:
            path: /opt
            state: absent
          ignore_errors: true

        - name: Emergency — unmount CephFS staging if mounted
          ansible.posix.mount:
            path: /mnt/cephfs_migrate
            state: absent
          ignore_errors: true

# ═══════════════════════════════════════════════════════════════════
# Play 4 — Log, notify, and stop test VM
# ═══════════════════════════════════════════════════════════════════
- name: Log, notify, and clean up test VM
  hosts: localhost
  gather_facts: false
  # ansible_date_time inherited from Play 1 fact cache — no re-gather needed
  vars_files:
    - vars/secrets.yaml
    - vars/vm_definitions.yaml
    - vars/semaphore_check.yaml

  tasks:
    - name: Resolve test result from host
      ansible.builtin.set_fact:
        _test_failed: "{{ hostvars[vm_definitions['cephfs-migrate-test'].vm_hostname]._test_failed | default(true) }}"
        _test_detail: "{{ hostvars[vm_definitions['cephfs-migrate-test'].vm_hostname]._test_detail | default('Play 3 did not run') }}"

    - name: Log migration test to MariaDB
      include_tasks: tasks/log_mariadb.yaml
      vars:
        log_table: maintenance
        log_application: "{{ source_host }}"
        log_hostname: "{{ controller_fqdn }}"
        log_type: "Servers"
        log_subtype: "CephFS Migration Test"
        log_status: "{{ 'failed' if _test_failed | bool else 'success' }}"

    - block:
        - name: Send Discord notification
          include_tasks: tasks/notify.yaml
          vars:
            discord_name: "CephFS Migration"
            discord_operation: "Test"
            discord_status: "{{ 'failed' if _test_failed | bool else 'successful' }}"
            discord_color: "{{ discord_color_failure if _test_failed | bool else discord_color_success }}"
            discord_url: "{{ semaphore_ext_url }}"
            discord_author: "{{ controller_fqdn }}"
            discord_fields:
              - name: "Source"
                value: "{{ source_host }}"
                inline: true
              - name: "CephFS Dir"
                value: "{{ vm_definitions['cephfs-migrate-test'].cephfs_host_dir }}"
                inline: true
              - name: "Detail"
                value: "{{ _test_detail }}"
      rescue:
        - ansible.builtin.fail:
            msg: "Discord notification failed. Re-run with -e debug_no_log=yes for details."

    - name: Stop test VM (skip with -e keep_vm=yes)
      community.general.proxmox_kvm:
        api_host: "{{ pve_api_host }}"
        api_user: "{{ pve_api_user }}"
        api_token_id: "{{ pve_api_token_id }}"
        api_token_secret: "{{ pve_api_token_secret }}"
        node: "{{ _vm_actual_node }}"
        vmid: "{{ vm_definitions['cephfs-migrate-test'].vm_id }}"
        state: stopped
        force: true
      no_log: "{{ not (debug_no_log | default(false) | bool) and (ansible_verbosity | default(0) | int < 3) }}"
      ignore_errors: true
      when: not (keep_vm | default('') == 'yes')

    - name: Fail play if migration test failed
      ansible.builtin.fail:
        msg: "CephFS migration test failed: {{ _test_detail }}"
      when: _test_failed | bool
