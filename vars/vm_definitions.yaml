# VM provisioning definitions and role derivations.
# Each entry maps vm_name → VM spec for Proxmox API.
# stack_roles and host_roles are derived dynamically from vm_definitions + host_definitions
# (see bottom of file). Non-VM hosts live in vars/host_definitions.yaml.

# Proxmox infrastructure defaults — shared across all VMs.
# pve_api_user, pve_api_token_id, pve_api_token_secret, pve_vm_password
# are secrets — defined in vars/secrets.yaml.
#
# Network topology and node names are deployment-specific and must be set in vault:
#   vault_pve_vip              — keepalived VIP (floating management IP for cluster API calls)
#   vault_vm_gateway           — default gateway IP for all VMs
#   vault_vm_dns               — DNS server IP for all VMs
#   vault_vm_search_domain     — DNS search domain (e.g. "homelab.local")
#   vault_pve_template_node    — PVE node where the cloud-init template config file lives
#   vault_test_vlan_id         — VLAN ID for test VM isolation (e.g. 88)
#   vault_test_vlan_gateway    — gateway IP on test isolation VLAN (e.g. "192.168.88.1")
#   vault_test_vlan_subnet     — network CIDR of test VLAN for firewall rules (e.g. "192.168.88.0/24")
#   vault_semaphore_ip         — Semaphore container static IP (SSH allow rule in setup_test_network.yaml)
#   vault_prod_lan_subnet      — production LAN CIDR to block from test VLAN (e.g. "192.168.1.0/24")
#   vault_pve_port_profile_name — Unifi switch port profile used by Proxmox uplinks
#   vault_test_vm_ip_prefix    — first 3 octets of test VM IPs (update to isolated subnet, e.g. "192.168.88.")
pve_api_host: "{{ vault_pve_vip }}"
pve_storage: "replicated"

pve_bridge: "vmbr0"
vm_user: "ansible"
vm_gateway: "{{ vault_vm_gateway }}"
vm_dns: "{{ vault_vm_dns }}"
vm_search_domain: "{{ vault_vm_search_domain }}"
vm_cidr: 24

# Cloud-init template — created automatically on first build.
# Ceph (replicated) storage is shared across all nodes, so one template serves the entire cluster.
# pve_api_host = vault_pve_vip (VIP). provision_vm.yaml resolves the actual node the VM
# lands on via the cluster resources API — safe regardless of which PVE node holds the VIP.
pve_template_vmid: 9000
pve_template_node: "{{ vault_pve_template_node }}"
pve_template_name: "ubuntu-cloud-template"
pve_cloud_image_url: "https://cloud-images.ubuntu.com/noble/current/noble-server-cloudimg-amd64.img"
vm_template_memory: 2048
vm_template_cores: 2

# Test VM slot pool — used by test-vm (and any future slot-based VMs).
# VMIDs: vm_test_slot_base .. vm_test_slot_base + vm_test_slot_count - 1
# IPs:   vault_test_vm_ip_prefix + (vault_test_vm_ip_offset + vm_index)
# To extend the pool or shift the VMID range, change these two values only.
vm_test_slot_base: 500
vm_test_slot_count: 10

# vm_definitions: keyed by role name (used as vm_name arg and for stack/role derivation).
# Hostnames are derived: <role>.{{ vault_vm_search_domain }}. Per-VM secrets from vault:
#   vault_vm_<role>_ip        — static IP for cloud-init network config
#   vault_vm_<role>_node      — PVE node to place this VM on
#
# test-vm uses a dedicated IP range to avoid updating secrets per build.
# Pass vm_index=0..vm_test_slot_count-1 (default 0) to select a slot:
#   vault_test_vm_ip_prefix   — first 3 octets with trailing dot (e.g. "10.10.10.")
#   vault_test_vm_ip_offset   — last octet of the first slot (e.g. 90)
# Resulting IPs: <prefix><offset+vm_index>  (e.g. 192.0.2.90 .. 192.0.2.99)
vm_definitions:
  core:
    vm_id: 300
    vm_name: core
    vm_mac: "02:00:00:00:01:04"       # static MAC — stable Unifi device identity across rebuilds
    vm_hostname: "core.{{ vault_vm_search_domain }}"
    vm_ip: "{{ vault_vm_core_ip | default('') }}"
    vm_cores: 4
    vm_memory_mb: 24576
    vm_disk_gb: 64
    pve_target_node: "{{ vault_vm_core_node | default('') }}"
    deploy_ssh_key: true
    nfs_exports:                       # export /opt to dev VIP (test VIP in DR, prod VIP in prod)
      - path: /opt
        clients: "{{ vault_dev_vip }}(ro,no_subtree_check,no_root_squash)"
    stacks: [infra, databases, auth, media]
    guacamole: { name: Core, group: Docker }

  apps:
    vm_id: 301
    vm_name: apps
    vm_mac: "02:00:00:00:01:05"       # static MAC — stable Unifi device identity across rebuilds
    vm_hostname: "apps.{{ vault_vm_search_domain }}"
    vm_ip: "{{ vault_vm_apps_ip | default('') }}"
    vm_cores: 4
    vm_memory_mb: 24576
    vm_disk_gb: 64
    pve_target_node: "{{ vault_vm_apps_node | default('') }}"
    deploy_ssh_key: true
    nfs_exports:                       # export /opt to dev VIP (test VIP in DR, prod VIP in prod)
      - path: /opt
        clients: "{{ vault_dev_vip }}(ro,no_subtree_check,no_root_squash)"
    stacks: [infra, apps, monitoring]
    guacamole: { name: Apps, group: Docker }

  dev:
    vm_id: 302
    vm_name: dev
    vm_mac: "02:00:00:00:01:06"       # static MAC — stable Unifi device identity across rebuilds
    vm_hostname: "dev.{{ vault_vm_search_domain }}"
    vm_ip: "{{ vault_vm_dev_ip | default('') }}"
    vm_cores: 2
    vm_memory_mb: 8192
    vm_disk_gb: 64
    pve_target_node: "{{ vault_vm_dev_node | default('') }}"
    deploy_ssh_key: true
    nfs_mounts:                        # NFS mounts from core/apps VIPs (test VIP in DR, prod VIP in prod)
      - src: "{{ vault_core_vip }}:/opt"
        path: "/mnt/nfs/core"
      - src: "{{ vault_apps_vip }}:/opt"
        path: "/mnt/nfs/apps"
    stacks: [infra, dev]
    guacamole: { name: Dev, group: Docker }

  amp:
    vm_id: 110
    vm_name: amp
    vm_mac: "02:00:00:00:01:10"       # static MAC — stable Unifi device identity across rebuilds
    vm_hostname: "amp.{{ vault_vm_search_domain }}"
    vm_ip: "{{ vault_vm_amp_ip | default('') }}"
    vm_cores: 4
    vm_memory_mb: 8192
    vm_disk_gb: 100
    pve_target_node: "{{ vault_vm_amp_node | default('') }}"
    guacamole: { name: AMP, group: Game Server }

  # Native graphical desktop VM — ubuntu-desktop-minimal installed during bootstrap.
  # Access via Proxmox VNC (pve_args) through Guacamole + Authentik groups.
  # No stacks — basic VM (OS + Network layers only via apply_role).
  # Vault secrets required before provisioning: vault_vm_desktop_ip, vault_vm_desktop_node
  desktop:
    vm_id: 303
    vm_name: desktop
    vm_mac: "02:00:00:00:01:07"       # static MAC — stable Unifi device identity across rebuilds
    vm_hostname: "desktop.{{ vault_vm_search_domain }}"
    vm_ip: "{{ vault_vm_desktop_ip | default('') }}"
    vm_cores: 4
    vm_memory_mb: 8192
    vm_disk_gb: 64
    pve_target_node: "{{ vault_vm_desktop_node | default('') }}"
    deploy_ssh_key: true
    vnc_display: 78                    # display :78 = port 5978 — merged into QEMU args by provision_vm.yaml
    guacamole: { name: Desktop, group: Hosted Desktops, protocol: vnc }

  # Hosted desktop VMs — VNC-only access through Guacamole + Authentik groups.
  # Not provisioned via build_ubuntu.yaml (manually created in Proxmox).
  # vm_id + vnc_display are the minimum fields needed for VNC connection resolution.
  macos:
    vm_id: 103
    vm_hostname: "macos.{{ vault_vm_search_domain }}"
    vnc_display: 79
    pve_args: >-
      -device isa-applesmc,osk="ourhardworkbythesewordsguardedpleasedontsteal(c)AppleComputerInc"
      -smbios type=2 -device usb-kbd,bus=ehci.0,port=2
      -global nec-usb-xhci.msi=off
      -global ICH9-LPC.acpi-pci-hotplug-with-bridge-support=off
      -cpu Haswell-noTSX,vendor=GenuineIntel,+invtsc,+hypervisor,kvm=on,vmware-cpuid-freq=on
    guacamole:
      name: MacOS
      group: Hosted Desktops
      protocol: vnc
      user_groups: [Guac-MacOS]

  freshjams:
    vm_id: 108
    vm_hostname: "freshjams.{{ vault_vm_search_domain }}"
    vnc_display: 77
    guacamole:
      name: FreshJams
      group: Hosted Desktops
      protocol: vnc
      user_groups: [Guac-FreshJams]

  personalfinance:
    vm_id: 100
    vm_hostname: "personalfinance.{{ vault_vm_search_domain }}"
    vnc_display: 80
    guacamole:
      name: PersonalFinance
      group: Hosted Desktops
      protocol: vnc

  test-vm:
    vm_id: "{{ (vm_test_slot_base + (vm_index | default(0) | int)) | int }}"
    vm_mac: "02:00:00:00:05:{{ '%02d' | format(vm_index | default(0) | int) }}"
    vm_name: "test-vm{{ vm_index | default(0) | int }}"
    vm_hostname: "test-vm{{ vm_index | default(0) | int }}.{{ vault_vm_search_domain | default('') }}"
    vm_ip: "{{ vault_test_vm_ip_prefix | default('') }}{{ (vault_test_vm_ip_offset | default(0) | int) + (vm_index | default(0) | int) }}"
    vm_cores: 2
    vm_memory_mb: 4096
    vm_disk_gb: 20
    pve_target_node: "{{ vm_node | default(pve_template_node) }}"
    vm_gateway: "{{ vault_test_vlan_gateway | default('') }}"   # isolated VLAN gateway (overrides global vm_gateway)
    vm_vlan_tag: "{{ vault_test_vlan_id | default('') }}"       # triggers VLAN tag on net0 in provision_vm.yaml
    # No ip_aliases — keepalived assigns role-specific test VIP on eth0 (docker_test_vip_offsets).
    # Cross-VM routing handled by SWAG config patching (tasks/patch_swag_confs.yaml).

# Optional per-VM fields (used by tasks/bootstrap_vm.yaml when defined):
#
#   nfs_mounts:                          # List of NFS mounts for /etc/fstab
#     - src: "192.0.2.10:/mnt/share"
#       path: "/mnt/nfs/share"
#       opts: "defaults,_netdev"         # optional, defaults to 'defaults,_netdev'
#
#   ufw_rules:                           # Additional UFW rules beyond SSH (always allowed)
#     - port: "8080"
#       proto: "tcp"                     # optional, defaults to 'tcp'
#       rule: "allow"                    # optional, defaults to 'allow'
#       src: "192.0.2.0/24"             # optional, restrict to source CIDR
#       comment: "Web UI"               # optional
#
#   ip_aliases:                          # IPs to alias on loopback (for test VMs with VLAN isolation)
#     - "192.0.2.50"                     # containers reaching this IP hit the local VM instead of prod
#     - "192.0.2.51"                     # persisted via netplan; survives reboots and OOM recovery
#
#   nfs_exports:                         # NFS server exports (installs nfs-kernel-server)
#     - path: "/opt"
#       clients: "10.0.0.50(ro,no_subtree_check,no_root_squash)"
#
# Optional per-VM provision fields (used by tasks/provision_vm.yaml when defined):
#
#   vm_mac: "02:00:00:00:01:04"         # static MAC on net0 — stable Unifi device identity across rebuilds
#                                        # use locally-administered prefix (02:xx); encode VMID in last bytes
#   vm_gateway: "192.0.2.1"             # overrides global vm_gateway (used in cloud-init ipconfig0)
#   vm_dns: "8.8.8.8,8.8.4.4"          # overrides global vm_dns (comma-separated, no spaces)
#   vm_vlan_tag: 88                      # if defined, sets VLAN tag on net0 via PVE API
#   vnc_display: 77                      # VNC display number — merged into QEMU args by provision_vm.yaml
#                                        # produces "-vnc 0.0.0.0:77" (port = 5900 + display)
#                                        # if pve_args is also defined, -vnc is appended to it
#   pve_args: "-cpu host"                # raw QEMU args — applied via PVE API during provisioning
#                                        # prefer vnc_display over pve_args for VNC-only use cases
#
#   guacamole:                           # metadata for maintain_guacamole.yaml auto-discovery
#     name: "Display Name"              # connection name in Guacamole UI
#     group: "Connection Group"         # connection group (Proxmox, Docker, unRAID, etc.)
#     protocol: vnc                     # optional — default is ssh; set vnc for VNC connections
#     user_groups: [Guac-MacOS]         # optional — Authentik user groups granted READ access
#                                       # omit for admin-only connections (guacamole_admin_groups)
#
#   stacks: [infra, databases, auth]     # ordered stack list — defines this VM as a Docker VM
#                                        # must be non-empty list or absent entirely (no stacks: [])
#   deploy_ssh_key: true                 # install ansible SSH key during bootstrap (default: false)

# Derived from vm_definitions + host_definitions — replaces static dicts that were
# maintained separately. Evaluated lazily by Ansible when accessed.
# host_definitions | default({}) allows playbooks that don't load host_definitions.yaml
# to still use these derivations (they produce VM-only results).

# stack_roles: role → ordered stack list.
# Includes all entries with a stacks key from both vm_definitions and host_definitions.
stack_roles: >-
  {{ dict(
    (vm_definitions | dict2items
     | selectattr('value.stacks', 'defined') | list
     + host_definitions | default({}) | dict2items
     | selectattr('value.stacks', 'defined') | list)
    | map(attribute='key')
    | zip(
      (vm_definitions | dict2items
       | selectattr('value.stacks', 'defined') | list
       + host_definitions | default({}) | dict2items
       | selectattr('value.stacks', 'defined') | list)
      | map(attribute='value.stacks')
    )
  ) }}

# Helper: all host entries with stacks, excluding test VMs (vm_vlan_tag).
# Used by host_roles below — avoids repeating the filter chain.
_host_entries: >-
  {{ vm_definitions | dict2items
     | rejectattr('value.vm_vlan_tag', 'defined')
     | selectattr('value.stacks', 'defined') | list
     + host_definitions | default({}) | dict2items
     | selectattr('value.stacks', 'defined') | list }}

# host_roles: hostname → role (replaces vault_vm_roles).
# Maps both internal (domain_local) and external (domain_ext) FQDNs so hosts
# work regardless of which domain is used in the inventory.
# Merges vm_definitions (Proxmox VMs) + host_definitions (VPS, NAS, legacy hosts).
host_roles: >-
  {{ dict(
    _host_entries | map(attribute='key')
    | map('regex_replace', '$', '.' ~ domain_local) | list
    | zip(_host_entries | map(attribute='key') | list)
  )
  | combine(dict(
    _host_entries | map(attribute='key')
    | map('regex_replace', '$', '.' ~ domain_ext) | list
    | zip(_host_entries | map(attribute='key') | list)
  )) }}
