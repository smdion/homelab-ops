# vars/secrets.yaml.example — expected vault keys
# Copy this file to vars/secrets.yaml, fill in your values, then encrypt:
#   cp vars/secrets.yaml.example vars/secrets.yaml
#   ansible-vault encrypt vars/secrets.yaml
#
# To edit later:  ansible-vault edit vars/secrets.yaml
# To view:        ansible-vault view vars/secrets.yaml

# Discord webhook — used by all playbook notifications
# Create a webhook in your Discord server: Server Settings → Integrations → Webhooks
# The webhook URL format is: https://discord.com/api/webhooks/{id}/{token}
discord_webhook_id: ""
discord_webhook_token: ""

# MariaDB logging database credentials
# The ansible_logging database stores all backup/update/maintenance/health records
logging_db_host: "10.0.0.1"
logging_db_port: 3306
logging_db_user: "ansible"
logging_db_password: ""
logging_db_name: "ansible_logging"

# Domain suffixes for hostname normalization and URL construction
# Internal: used to match inventory_hostname (e.g., "home.local")
# External: used to build clickable URLs in Discord embeds (e.g., "example.com")
domain_local: "home.local"
domain_ext: "example.com"

# Semaphore API — used by maintain_health.yaml to check for failed tasks
# Generate a token in Semaphore: User menu → API Tokens
semaphore_api_token: ""

# Semaphore internal URL — used for API calls (not exposed externally)
# This should be the IP/port Semaphore listens on, reachable from the Ansible controller
semaphore_host_url: "http://10.0.0.1:3000"

# Controller hostname — short hostname of the Semaphore controller (used to build controller_fqdn)
semaphore_controller_hostname: "mycontroller"

# DB host FQDNs — used by restore playbooks for cross-host delegate_to
# These are the inventory_hostname values of hosts running DB containers
db_host_primary: "dbhost1.home.local"
db_host_secondary: "dbhost2.home.local"

# --- Optional: only needed if using specific playbooks ---

# MeTube Discord webhook — separate channel for per-video download notifications
# Only needed if using download_videos.yaml
# discord_download_webhook_id: ""
# discord_download_webhook_token: ""

# Apprise — optional alternative/additional notification routing
# Supports 60+ services (Telegram, ntfy, Gotify, Slack, Pushover, etc.)
# Use CLI mode, API mode, or both simultaneously.
#
# CLI mode: requires 'apprise' installed on the Ansible controller (pip install apprise)
# Space-separated list of Apprise service URLs.
# Full list: https://github.com/caronc/apprise#supported-notifications
# apprise_urls: "tgram://bottoken/chatid ntfy://ntfy.example.com/topic"
#
# API mode: requires a running Apprise API instance (docker: caronc/apprise-api)
# apprise_api_url: "http://apprise-api:8000"
# apprise_api_key: "ansible"   # matches the key configured in the Apprise API (default: ansible)

# Unifi Protect API key — only needed if backing up a UNVR via backup_hosts.yaml
# unvr_api_key: ""

# SSH public key for the ansible user — only needed if using setup_ansible_user.yaml or maintain_pve.yaml
# ansible_user_ssh_pubkey: "ssh-ed25519 AAAA..."

# SSH private key for the ansible user — deployed to VMs when build_ubuntu.yaml is run with -e deploy_ssh_key=yes.
# Allows VMs to SSH to each other and run playbooks without Semaphore (e.g. during migration or outage).
# Paste the same private key from Semaphore Key Store (ID=8, "ansible").
# ansible_user_ssh_private_key: |
#   -----BEGIN OPENSSH PRIVATE KEY-----
#   ...
#   -----END OPENSSH PRIVATE KEY-----

# Home Assistant — only needed if using backup_offline.yaml
# ha_url: "http://10.0.0.10:8123"
# ha_bearer_token: ""
# ha_dsm_automation: "automation.backup_synology_dsm"
# ha_shutdown_button: "button.synology_shutdown"

# Synology NAS credentials — only needed if using backup_offline.yaml
# synology_ip: "10.0.0.50"
# synology_mac: "AA:BB:CC:DD:EE:FF"
# synology_name: "synology"

# Backblaze B2 offsite backup — only needed if using backup_offsite.yaml
# Create a B2 bucket and application key in the Backblaze web console.
# Use an application key scoped to a single bucket (principle of least privilege).
# Capabilities needed: listBuckets, listFiles, readFiles, writeFiles, deleteFiles
# b2_account_id: ""           # B2 keyID (not the master application key ID)
# b2_application_key: ""      # B2 applicationKey
# b2_bucket_name: ""          # e.g., "homelab-backup-offsite"

# VPS FQDN — only needed if using maintain_unifi.yaml with external VPS
# vps_fqdn: "vps.example.com"

# Grafana API — only needed if using deploy_grafana.yaml
# Create a service account in Grafana (Administration → Service Accounts) with Editor role.
# Generate a token and paste it here. The URL must be reachable from the Semaphore controller.
# grafana_url: "http://grafana-host:3000"
# grafana_service_account_token: ""

# Uptime Kuma push URL — only needed if using REL-3 dead man's switch monitoring
# Set up a Push monitor in Uptime Kuma, copy the push URL here
# uptime_kuma_push_url: "https://uptime.example.com/api/push/xxxx"

# --- Docker stack secrets (deploy_stacks.yaml) ---
# These are referenced in stacks/*/env.j2 templates.
# Values come from the current .env files on each host.

# Database passwords — per-engine, shared across stacks
# docker_mariadb_password: ""
# docker_postgres_password: ""

# infra stack
# docker_beszel_key: "ssh-ed25519 AAAA..."

# auth stack — Authentik
# docker_authentik_secret_key: ""
# docker_trusted_proxy_cidrs: "172.16.0.0/12"   # CIDR(s) of reverse proxy (Authentik trusted proxy)

# auth stack — Email (SMTP via Authentik)
# docker_email_host and docker_email_port are in vars/docker_stacks.yaml (not secrets)
# docker_email_username: ""
# docker_email_password: ""
# docker_email: ""

# auth stack — SWAG (DNS validation + bouncer + GeoIP)
# docker_cloudflare_api_key: ""
# docker_crowdsec_api_key: ""
# docker_maxmind_license_key: ""
# docker_maxmind_user_id: ""

# monitoring stack — Grafana
# docker_grafana_admin_password: ""
# docker_grafana_oauth_client_id: ""
# docker_grafana_oauth_client_secret: ""

# vpn stack — WireGuard
# vault_wg_internal_subnet: "10.0.0.0/24"       # WG_INTERNAL_SUBNET for wireguard container

# --- Docker VM VIPs + Keepalived (bootstrap_vm.yaml, templates/keepalived-docker.conf.j2) ---
# Each role VM gets a floating VIP via keepalived.
# vault_core_vip: "10.0.0.50"
# vault_apps_vip: "10.0.0.51"
# vault_dev_vip: "10.0.0.52"
# vault_docker_vrrp_password: "changeme"
# vault_docker_vrrp_priorities:            # short hostname → integer priority (highest = MASTER)
#   core: 150
#   apps: 150
#   dev: 150

# --- Role mapping ---
# vm_roles is now derived from vm_definitions (vars/vm_definitions.yaml).
# No vault entry needed — hostnames derived from role name + vault_vm_search_domain.

# --- VM provisioning secrets (build_ubuntu.yaml) ---
# Proxmox API credentials for community.general.proxmox_kvm
# Create an API token in Proxmox: Datacenter → API Tokens
#
# vault_pve_vip is the keepalived floating VIP — used as pve_api_host in vm_definitions.yaml.
# Network topology vars (vault_vm_gateway, vault_vm_dns, etc.) also required — see vm_definitions.yaml.

# vault_pve_vip: "10.0.0.1"       # keepalived VIP (floating management IP)
# vault_vm_gateway: "10.0.0.1"
# vault_vm_dns: "10.0.0.1"
# vault_vm_search_domain: "home.local"
# vault_pve_template_node: "nodename"
# pve_api_user: "root@pam"
# pve_api_token_id: "ansible"
# pve_api_token_secret: ""
# pve_vm_password: ""
#
# Per-VM secrets (keyed by role — see vm_definitions.yaml):
# Hostnames are derived (<role>.{{ vault_vm_search_domain }}) — no vault entry needed.
# vault_vm_core_ip: "10.0.0.15"
# vault_vm_core_node: "pve-node1"
# vault_vm_apps_ip: "10.0.0.16"
# vault_vm_apps_node: "pve-node2"
# vault_vm_dev_ip: "10.0.0.17"
# vault_vm_dev_node: "pve-node1"
# vault_vm_amp_ip: "10.0.0.20"
# vault_vm_amp_node: "pve-node3"
#
# VPS NFS IP — used by dev stack override (code-server VPS workspace mount)
# vault_vps_nfs_ip: "10.0.0.100"

# --- Test VM network isolation (setup_test_network.yaml, build_ubuntu.yaml, test_restore.yaml, test_backup_restore.yaml) ---
# PREREQUISITE: manually add vault_test_vlan_id to the Proxmox uplink port profile in Unifi UI first.
# See DESIGN.md "Test VM Network Isolation" for exact steps.
# vault_test_vlan_id: 88                           # VLAN ID for test-isolation network
# vault_test_vlan_gateway: "192.168.88.1"          # gateway IP on test VLAN (Unifi ip_subnet field)
# vault_test_vlan_subnet: "192.168.88.0/24"        # network CIDR (firewall rule src/dst address)
# vault_pve_port_profile_name: "Servers-Trunk"    # Unifi switch port profile used by Proxmox uplinks
# vault_test_vm_ip_prefix: "192.168.88."          # update from prod prefix to isolated subnet prefix
# Semaphore IP and prod LAN CIDR are derived from existing vars (semaphore_host_url, vault_vm_gateway)
