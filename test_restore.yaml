---
# Automated restore testing on a disposable VM.
# Builds VM if needed, restores source host's appdata, deploys stacks,
# verifies container health, and reverts to clean state.
# Also serves as a DR recovery tool via -e dr_mode=yes.
#
# Usage:
#   # Test controller's full stack (local /opt)
#   ansible-playbook test_restore.yaml -e vm_name=test-vm -e source_host=<controller-fqdn>
#
#   # Test restore on CephFS-backed /opt (auto-creates CephFS dir + mounts during bootstrap)
#   ansible-playbook test_restore.yaml -e vm_name=cephfs-migrate-test -e source_host=<role-fqdn>
#
#   # Test single app restore
#   ansible-playbook test_restore.yaml -e vm_name=test-vm -e source_host=<controller-fqdn> -e restore_app=authentik
#
#   # Test single stack deploy
#   ansible-playbook test_restore.yaml -e vm_name=test-vm -e source_host=<source-fqdn> -e deploy_stack=media
#
#   # DR recovery (keeps restored state, no revert)
#   ansible-playbook test_restore.yaml -e vm_name=test-vm -e source_host=<controller-fqdn> -e dr_mode=yes
#
# Required extra vars:
#   vm_name      — ephemeral VM key from vm_definitions (use "test-vm" for local /opt, or
#                  "cephfs-migrate-test" for CephFS-backed /opt). Do NOT use permanent VM keys.
#   source_host  — inventory_hostname of source host in stack_assignments
#
# Optional extra vars:
#   backup_source — hostname for monolithic archive fallback (defaults to source_host).
#                   Stack and DB archives use stack-based folders (/backup/{stack}/).
#
# VM lifecycle (provision_vm.yaml is idempotent):
#   - If the VMID doesn't exist, the VM is provisioned from the cloud-init template
#   - If the VMID already exists (e.g. from a prior partial run), clone is skipped and
#     provisioning resumes from configure/start — no manual cleanup needed
#   - Node resolution uses the cluster resources API — VIP-safe regardless of which
#     PVE node is currently MASTER
#   - After restore: snapshot is reverted, VM stays running and ready for next test
#   - In dr_mode=yes: no revert — VM keeps the restored state for real DR recovery
#
# Optional extra vars:
#   vm_index=N    — test-vm slot 0..9; auto-detected (lowest non-running slot) if omitted
#   restore_app   — single app name to selectively extract from archive
#   deploy_stack  — single stack to deploy
#   dr_mode=yes   — DR recovery mode (skip snapshot/revert, keep state)
#   skip_dbs      — comma-separated DB names to skip restoring (e.g. -e skip_dbs=nextcloud)
#   backup_source — comma-separated backup dir names to search (e.g. -e backup_source=tantiveiv.seandion.local,odyssey.seandion.local)

# ═══════════════════════════════════════════════════════════════════
# Play 1 — Prepare: Validate, find backup, build VM if needed, snapshot
# ═══════════════════════════════════════════════════════════════════
- name: Prepare test restore
  hosts: localhost
  gather_facts: true
  gather_subset: ['!all', 'date_time']
  vars_files:
    - vars/secrets.yaml
    - vars/proxmox.yaml
    - vars/docker_stacks.yaml
    - vars/vm_definitions.yaml
    - vars/semaphore_check.yaml
  vars:
    maintenance_name: "Docker"
    maintenance_type: "Servers"
    maintenance_subtype: "Test Restore"

  pre_tasks:
    - name: Assert vm_name exists in vm_definitions
      ansible.builtin.assert:
        that:
          - vm_name is defined
          - vm_name in vm_definitions
        fail_msg: >-
          vm_name '{{ vm_name | default('undefined') }}' not found in vm_definitions.
          Valid names: {{ vm_definitions.keys() | list | join(', ') }}

    - name: Assert source_host exists in stack_assignments
      ansible.builtin.assert:
        that:
          - source_host is defined
          - source_host in stack_assignments
        fail_msg: >-
          source_host '{{ source_host | default('undefined') }}' not found in stack_assignments.
          Valid hosts: {{ stack_assignments.keys() | list | join(', ') }}

    - name: Assert MariaDB logging database is reachable
      include_tasks: tasks/assert_db_connectivity.yaml

    - name: Log playbook run context to MariaDB
      include_tasks: tasks/log_run_context.yaml
      vars:
        log_playbook: "test_restore.yaml"
        log_hostname: "{{ controller_fqdn }}"
        log_run_vars: "{{ {'vm_name': vm_name | default('')} | to_json }}"

  tasks:
    - name: Auto-detect free vm_index for test-vm pool
      include_tasks: tasks/resolve_test_vm_index.yaml
      when: vm_name in ['test-vm', 'cephfs-migrate-test']

    - name: Resolve VM and stack configuration
      ansible.builtin.set_fact:
        _vm: "{{ vm_definitions[vm_name] }}"
        _backup_sources: "{{ (backup_source | default(source_host)).split(',') }}"
        _stacks: >-
          {{ [deploy_stack] if deploy_stack | default('') | length > 0
             else stack_assignments[source_host] }}

    # ===== AUTO-CREATE CEPHFS DIR (when vm has cephfs_host_dir) =====
    - name: Add PVE host to in-memory inventory (for CephFS dir creation)
      ansible.builtin.add_host:
        name: pve_builder
        ansible_host: "{{ pve_api_host }}"
        ansible_user: ansible
      when: _vm.cephfs_host_dir is defined

    - name: Ensure test VM CephFS directory exists (isolated from production)
      ansible.builtin.shell: |
        set -e
        MOUNT_DIR=$(mktemp -d)
        ADMIN_KEY=$(ceph auth print-key client.admin)
        mount -t ceph {{ vault_ceph_mons }}:/ "$MOUNT_DIR" \
          -o "name=admin,secret=${ADMIN_KEY}"
        if [ -d "$MOUNT_DIR/{{ _vm.cephfs_host_dir }}" ]; then
          echo "exists"
        else
          mkdir "$MOUNT_DIR/{{ _vm.cephfs_host_dir }}"
          echo "created"
        fi
        umount "$MOUNT_DIR"
        rmdir "$MOUNT_DIR"
      args:
        executable: /bin/bash
      delegate_to: pve_builder
      become: true
      register: _cephfs_dir_result
      changed_when: "'created' in _cephfs_dir_result.stdout"
      no_log: "{{ not (debug_no_log | default(false) | bool) and (ansible_verbosity | default(0) | int < 3) }}"
      when: _vm.cephfs_host_dir is defined

    # ===== FIND BACKUP ARCHIVES =====
    # Requires the container user to have read access to the /backup/ bind
    # mount (e.g. via group_add: 100 for the users group on unRAID).
    - name: Find per-stack backup archives from production backups (read-only)
      ansible.builtin.shell: >
        ls -t {{ backup_base_dir }}/{{ item }}/backup_{{ item }}_*.tar.gz 2>/dev/null | head -1
      loop: "{{ _stacks }}"
      register: _per_stack_archives
      become: false
      changed_when: false
      check_mode: false

    - name: Set per-stack archive list
      ansible.builtin.set_fact:
        _archive_files: "{{ _per_stack_archives.results | selectattr('stdout', 'ne', '') | map(attribute='stdout') | list }}"

    - name: Fall back to monolithic archive
      ansible.builtin.shell: >
        ls -t {% for src in _backup_sources %}{{ backup_base_dir }}/{{ src }}/backup_*.tar.gz {% endfor %}2>/dev/null | head -1
      register: _monolithic_archive
      become: false
      changed_when: false
      check_mode: false
      when: _archive_files | length == 0

    - name: Use monolithic archive as fallback
      ansible.builtin.set_fact:
        _archive_files: "{{ [_monolithic_archive.stdout] }}"
      when:
        - _archive_files | length == 0
        - _monolithic_archive.stdout | default('') | length > 0

    - name: Assert backup archives exist
      ansible.builtin.assert:
        that: _archive_files | length > 0
        fail_msg: "No backup archives found for stacks {{ _stacks | join(', ') }} (also checked monolithic in {{ _backup_sources | join(', ') }})"

    # ===== FIND DB SQL DUMP ARCHIVES =====
    # Load each DB vars file and capture config into explicit facts (include_vars
    # with name: has scoping issues where the namespaced dict is empty in
    # subsequent loop expressions).
    - name: Load postgres DB config
      ansible.builtin.include_vars:
        file: vars/db_primary_postgres.yaml
      when: "'databases' in _stacks"

    - name: Save postgres DB config
      ansible.builtin.set_fact:
        _db_postgres_all_names: "{{ db_names }}"
        _db_postgres_container: "{{ db_container_name }}"
        _db_postgres_username: "{{ db_username }}"
      when: "'databases' in _stacks"

    - name: Load mariadb DB config
      ansible.builtin.include_vars:
        file: vars/db_primary_mariadb.yaml
      when: "'databases' in _stacks"

    - name: Save mariadb DB config
      ansible.builtin.set_fact:
        _db_mariadb_all_names: "{{ db_names }}"
        _db_mariadb_container: "{{ db_container_name }}"
        _db_mariadb_username: "{{ db_username }}"
      when: "'databases' in _stacks"

    - name: Filter skipped DBs from restore lists
      ansible.builtin.set_fact:
        _db_postgres_all_names: "{{ _db_postgres_all_names | difference(skip_dbs.split(',')) }}"
        _db_mariadb_all_names: "{{ _db_mariadb_all_names | difference(skip_dbs.split(',')) }}"
      when:
        - skip_dbs | default('') | length > 0
        - "'databases' in _stacks"

    - name: Default DB facts when databases stack absent
      ansible.builtin.set_fact:
        _db_postgres_all_names: []
        _db_mariadb_all_names: []
        _db_postgres_container: ""
        _db_mariadb_container: ""
        _db_postgres_username: ""
        _db_mariadb_username: ""
      when: "'databases' not in _stacks"

    - name: Find latest SQL dump per database — {{ item }}
      ansible.builtin.shell: >
        ls -t {{ backup_base_dir }}/databases/backup_{{ item }}_*.sql {{ backup_base_dir }}/databases/backup_{{ item }}_*.sql.gz 2>/dev/null | head -1
      loop: "{{ _db_postgres_all_names + _db_mariadb_all_names }}"
      register: _db_dump_results
      become: false
      changed_when: false
      check_mode: false
      when: (_db_postgres_all_names + _db_mariadb_all_names) | length > 0

    - name: Build DB archive map and name lists
      ansible.builtin.set_fact:
        _db_archive_map: >-
          {{ dict(_db_dump_results.results | default([])
                  | selectattr('stdout', 'defined')
                  | selectattr('stdout', 'ne', '')
                  | map(attribute='item') | list
                  | zip(_db_dump_results.results | default([])
                        | selectattr('stdout', 'defined')
                        | selectattr('stdout', 'ne', '')
                        | map(attribute='stdout') | list)) }}
        _db_postgres_names: >-
          {{ _db_dump_results.results | default([])
             | selectattr('stdout', 'defined')
             | selectattr('stdout', 'ne', '')
             | map(attribute='item') | list
             | intersect(_db_postgres_all_names) }}
        _db_mariadb_names: >-
          {{ _db_dump_results.results | default([])
             | selectattr('stdout', 'defined')
             | selectattr('stdout', 'ne', '')
             | map(attribute='item') | list
             | intersect(_db_mariadb_all_names) }}

    - name: Report DB backup discovery
      ansible.builtin.debug:
        msg: >-
          DB dumps found: {{ _db_archive_map | length }}/{{ (_db_postgres_all_names + _db_mariadb_all_names) | length }}.
          Postgres: {{ _db_postgres_names | join(', ') or 'none' }}.
          MariaDB: {{ _db_mariadb_names | join(', ') or 'none' }}.
          {{ _db_archive_map | to_nice_yaml if _db_archive_map | length > 0 else '' }}

    - name: Verify archive integrity
      ansible.builtin.shell: gunzip -t "{{ item }}"
      loop: "{{ _archive_files }}"
      become: false
      changed_when: false
      check_mode: false

    # ===== RESOLVE OR PROVISION VM =====
    - name: Resolve or provision test VM
      include_tasks: tasks/resolve_or_provision_vm.yaml

# ═══════════════════════════════════════════════════════════════════
# Play 2 — Bootstrap (new VM or Docker missing)
# ═══════════════════════════════════════════════════════════════════
- name: Bootstrap test VM
  hosts: test_target
  become: true
  gather_facts: false
  vars_files:
    - vars/secrets.yaml
    - vars/vm_definitions.yaml
    - vars/docker_vips.yaml

  tasks:
    - name: Wait for system boot to complete
      ansible.builtin.wait_for_connection:
        delay: 5
        timeout: 300

    - name: Gather facts
      ansible.builtin.setup:

    - name: Inject test VM role (test_vm_role override)
      ansible.builtin.set_fact:
        vault_vm_roles: "{{ vault_vm_roles | combine({inventory_hostname: test_vm_role}) }}"
        vault_docker_vrrp_priorities: >-
          {{ vault_docker_vrrp_priorities | default({})
             | combine({inventory_hostname.split('.')[0]: 100}) }}
      when: test_vm_role is defined

    - name: Check if Docker is installed
      ansible.builtin.command: docker --version
      register: _docker_check
      failed_when: false
      changed_when: false
      become: false

    - name: Bootstrap Ubuntu with Docker and security hardening
      include_tasks: tasks/bootstrap_vm.yaml
      vars:
        _vm: "{{ hostvars['localhost']._vm }}"
      when: hostvars[inventory_hostname]._needs_bootstrap | default(false) or _docker_check.rc != 0

# ═══════════════════════════════════════════════════════════════════
# Play 3 — Snapshot clean post-bootstrap state for revert
# ═══════════════════════════════════════════════════════════════════
- name: Create pre-test snapshot
  hosts: localhost
  gather_facts: false
  vars_files:
    - vars/secrets.yaml
    - vars/vm_definitions.yaml

  tasks:
    - name: Get existing snapshots
      ansible.builtin.uri:
        url: "https://{{ pve_api_host }}:8006/api2/json/nodes/{{ _vm_actual_node }}/qemu/{{ vm_definitions[vm_name].vm_id }}/snapshot"
        method: GET
        headers:
          Authorization: "PVEAPIToken={{ pve_api_user }}!{{ pve_api_token_id }}={{ pve_api_token_secret }}"
        validate_certs: false
      no_log: "{{ not (debug_no_log | default(false) | bool) and (ansible_verbosity | default(0) | int < 3) }}"
      register: _vm_snapshots
      when: not (dr_mode | default('') == 'yes')

    - name: Delete existing pre-test snapshot if present
      ansible.builtin.uri:
        url: "https://{{ pve_api_host }}:8006/api2/json/nodes/{{ _vm_actual_node }}/qemu/{{ vm_definitions[vm_name].vm_id }}/snapshot/pre-test-restore"
        method: DELETE
        headers:
          Authorization: "PVEAPIToken={{ pve_api_user }}!{{ pve_api_token_id }}={{ pve_api_token_secret }}"
        validate_certs: false
      no_log: "{{ not (debug_no_log | default(false) | bool) and (ansible_verbosity | default(0) | int < 3) }}"
      when:
        - not (dr_mode | default('') == 'yes')
        - _vm_snapshots.json.data | selectattr('name', 'equalto', 'pre-test-restore') | list | length > 0

    - name: Wait for VM lock to clear after snapshot delete
      ansible.builtin.uri:
        url: "https://{{ pve_api_host }}:8006/api2/json/nodes/{{ _vm_actual_node }}/qemu/{{ vm_definitions[vm_name].vm_id }}/status/current"
        method: GET
        headers:
          Authorization: "PVEAPIToken={{ pve_api_user }}!{{ pve_api_token_id }}={{ pve_api_token_secret }}"
        validate_certs: false
      register: _vm_lock_status
      until: _vm_lock_status.json.data.lock is not defined
      retries: 20
      delay: 3
      no_log: "{{ not (debug_no_log | default(false) | bool) and (ansible_verbosity | default(0) | int < 3) }}"
      when:
        - not (dr_mode | default('') == 'yes')
        - _vm_snapshots.json.data | selectattr('name', 'equalto', 'pre-test-restore') | list | length > 0

    - name: Create pre-test snapshot (post-bootstrap clean state)
      ansible.builtin.uri:
        url: "https://{{ pve_api_host }}:8006/api2/json/nodes/{{ _vm_actual_node }}/qemu/{{ vm_definitions[vm_name].vm_id }}/snapshot"
        method: POST
        headers:
          Authorization: "PVEAPIToken={{ pve_api_user }}!{{ pve_api_token_id }}={{ pve_api_token_secret }}"
        body_format: form-urlencoded
        body:
          snapname: pre-test-restore
          vmstate: 0
        validate_certs: false
      no_log: "{{ not (debug_no_log | default(false) | bool) and (ansible_verbosity | default(0) | int < 3) }}"
      when: not (dr_mode | default('') == 'yes')

# ═══════════════════════════════════════════════════════════════════
# Play 4 — Deploy, Restore, and Health Check
# ═══════════════════════════════════════════════════════════════════
- name: Test restore on VM
  hosts: test_target
  become: true
  gather_facts: true
  gather_subset: ['!all', 'date_time']
  vars_files:
    - vars/secrets.yaml
    - vars/docker_stacks.yaml
    - vars/docker_vips.yaml
    - vars/vm_definitions.yaml
    - vars/semaphore_check.yaml
  vars:
    maintenance_name: "Docker"
    maintenance_type: "Servers"
    maintenance_subtype: "Test Restore"
    backup_tmp_dir: "/tmp"

  tasks:
    - name: Assert /opt is not production CephFS (safety gate)
      include_tasks: tasks/assert_test_vm.yaml

    - name: Inject test VM role (test_vm_role override)
      ansible.builtin.set_fact:
        vault_vm_roles: "{{ vault_vm_roles | combine({inventory_hostname: test_vm_role}) }}"
        vault_docker_vrrp_priorities: >-
          {{ vault_docker_vrrp_priorities | default({})
             | combine({inventory_hostname.split('.')[0]: 100}) }}
      when: test_vm_role is defined

    - name: Initialize restore state
      ansible.builtin.set_fact:
        _restore_test_failed: false
        _restore_test_detail: ""

    - name: Stop and remove all containers before CephFS cleanup
      ansible.builtin.shell: |
        docker ps -aq | xargs -r docker rm -f 2>/dev/null || true
      become: true
      when:
        - hostvars['localhost']._vm.cephfs_host_dir is defined

    - name: Clean test VM CephFS appdata (/opt on test VM only)
      become: true
      ansible.builtin.shell: |
        find /opt -mindepth 1 -maxdepth 1 -exec rm -rf {} +
      when:
        - hostvars['localhost']._vm.cephfs_host_dir is defined

    - name: Ensure shared Docker network exists
      community.docker.docker_network:
        name: homelab
        state: present
      become: true

    - block:
        # ===== EXTRACT APPDATA FROM BACKUP =====
        - name: Ensure backup_tmp_dir exists on test VM
          ansible.builtin.file:
            path: "{{ backup_tmp_dir }}"
            state: directory
            mode: '0755'
          become: true

        - name: Compute selective extract path
          ansible.builtin.set_fact:
            _extract_path: "{{ (src_raw_files[0] | regex_replace('^/', '')) + '/' + restore_app }}"
          when: restore_app | default('') | length > 0

        - name: Restore appdata from production backup to test VM
          include_tasks: tasks/restore_appdata.yaml
          loop: "{{ hostvars['localhost']._archive_files }}"
          loop_control:
            loop_var: _current_archive
          vars:
            _restore_archive_path: "{{ _current_archive }}"
            _restore_mode: inplace
            _restore_extract_path: "{{ _extract_path | default('') }}"
            _restore_app_name: "{{ restore_app | default('') }}"

        # ===== PATCH SWAG SITE-CONFS FOR NEW VM LAYOUT =====
        # Restored SWAG configs reference old host IPs (tantive-iv/odyssey).
        # Patch them to use Docker service names (same-VM) and VIPs (cross-VM).
        - name: Patch SWAG site-confs for core/apps/dev layout
          include_tasks: tasks/patch_swag_confs.yaml
          vars:
            _core_vip: >-
              {% if test_vm_role is defined %}{{ ansible_default_ipv4.address.rsplit('.', 1)[0] }}.{{ docker_test_vip_offsets['core'] }}{% else %}{{ vault_core_vip }}{% endif %}
            _apps_vip: >-
              {% if test_vm_role is defined %}{{ ansible_default_ipv4.address.rsplit('.', 1)[0] }}.{{ docker_test_vip_offsets['apps'] }}{% else %}{{ vault_apps_vip }}{% endif %}
            _dev_vip: >-
              {% if test_vm_role is defined %}{{ ansible_default_ipv4.address.rsplit('.', 1)[0] }}.{{ docker_test_vip_offsets['dev'] }}{% else %}{{ vault_dev_vip }}{% endif %}
          when: "'auth' in hostvars['localhost']._stacks"

        # ===== DEPLOY DATABASES STACK FIRST =====
        # DB containers must be running and populated before app stacks start,
        # otherwise apps (authentik, jellyseerr, etc.) connect to empty databases.
        - name: Deploy databases stack first
          include_tasks: tasks/deploy_single_stack.yaml
          vars:
            _current_stack: databases
            _test_mode: true
            patch_compose_networks: true
            _apps_vip: >-
              {% if test_vm_role is defined %}{{ ansible_default_ipv4.address.rsplit('.', 1)[0] }}.{{ docker_test_vip_offsets['apps'] }}{% else %}{{ vault_apps_vip }}{% endif %}
          when: "'databases' in hostvars['localhost']._stacks"

        - name: Reset DB passwords to match vault (restored data may differ)
          include_tasks: tasks/reset_db_auth.yaml
          vars:
            _db_mariadb_password: "{{ db_password }}"
            _db_postgres_password: "{{ docker_postgres_password }}"
          when: "'databases' in hostvars['localhost']._stacks"

        # ===== RESTORE SQL DUMPS =====
        - name: Wait for database containers to accept authenticated connections
          ansible.builtin.shell: |
            found_any=false
            for i in $(seq 1 60); do
              all_ready=true
              if docker ps -q --filter "name=postgres" | grep -q .; then
                found_any=true
                docker exec postgres pg_isready -U postgres >/dev/null 2>&1 || all_ready=false
              fi
              if docker ps -q --filter "name=mariadb" | grep -q .; then
                found_any=true
                docker exec -e MYSQL_PWD="$DB_PASSWORD" mariadb mysql -u root -e "SELECT 1" >/dev/null 2>&1 || all_ready=false
              fi
              if $found_any && $all_ready; then
                echo "ready"
                exit 0
              fi
              sleep 2
            done
            echo "timeout — found_any=$found_any"
            exit 1
          environment:
            DB_PASSWORD: "{{ db_password | default('') }}"
          become: true
          changed_when: false
          when: hostvars['localhost']._db_archive_map | default({}) | length > 0

        - name: Create DB restore staging directory on test VM
          ansible.builtin.file:
            path: /tmp/db_restore_staging
            state: directory
            mode: '0755'
          become: true
          when: hostvars['localhost']._db_archive_map | default({}) | length > 0

        - name: Copy production DB backup to test VM — {{ item.key }}
          ansible.builtin.synchronize:
            src: "{{ item.value }}"
            dest: "/tmp/db_restore_staging/{{ item.value | basename }}"
            compress: false
            rsync_opts:
              - "--contimeout=30"
              - "--timeout=60"
              - "--whole-file"
          become: true
          ignore_errors: true
          register: _db_rsync_result
          loop: "{{ hostvars['localhost']._db_archive_map | default({}) | dict2items }}"
          loop_control:
            label: "{{ item.key }}"
          when: hostvars['localhost']._db_archive_map | default({}) | length > 0

        - name: "Rsync stalled — copy DB backup via Ansible — {{ item.key }}"
          ansible.builtin.copy:
            src: "{{ item.value }}"
            dest: "/tmp/db_restore_staging/{{ item.value | basename }}"
            mode: "0644"
          become: true
          loop: "{{ hostvars['localhost']._db_archive_map | default({}) | dict2items }}"
          loop_control:
            label: "{{ item.key }}"
          when:
            - hostvars['localhost']._db_archive_map | default({}) | length > 0
            - _db_rsync_result is failed

        - name: Restore postgres database — {{ _db_item }}
          include_tasks: tasks/db_restore.yaml
          loop: "{{ hostvars['localhost']._db_postgres_names | default([]) }}"
          loop_control:
            loop_var: _db_item
          vars:
            _db_name: "{{ _db_item }}"
            _db_container: "{{ hostvars['localhost']._db_postgres_container }}"
            _db_username: "{{ hostvars['localhost']._db_postgres_username }}"
            _db_password: "{{ db_password | default('') }}"
            _db_source_file: "/tmp/db_restore_staging/{{ hostvars['localhost']._db_archive_map[_db_item] | basename }}"
            _db_is_postgres: true
            _db_is_mariadb: false
            _db_is_influxdb: false
            _db_tmp_dir: "/tmp/db_restore_staging"
          when: hostvars['localhost']._db_postgres_names | default([]) | length > 0

        - name: Restore mariadb database — {{ _db_item }}
          include_tasks: tasks/db_restore.yaml
          loop: "{{ hostvars['localhost']._db_mariadb_names | default([]) }}"
          loop_control:
            loop_var: _db_item
          vars:
            _db_name: "{{ _db_item }}"
            _db_container: "{{ hostvars['localhost']._db_mariadb_container }}"
            _db_username: "{{ hostvars['localhost']._db_mariadb_username }}"
            _db_password: "{{ db_password | default('') }}"
            _db_source_file: "/tmp/db_restore_staging/{{ hostvars['localhost']._db_archive_map[_db_item] | basename }}"
            _db_is_postgres: false
            _db_is_mariadb: true
            _db_is_influxdb: false
            _db_tmp_dir: "/tmp/db_restore_staging"
          when: hostvars['localhost']._db_mariadb_names | default([]) | length > 0

        - name: Clean up DB restore staging directory
          ansible.builtin.file:
            path: /tmp/db_restore_staging
            state: absent
          become: true
          when: hostvars['localhost']._db_archive_map | default({}) | length > 0

        # ===== DEPLOY REMAINING STACKS =====
        - name: "Deploy stack — {{ _current_stack }}"
          include_tasks: tasks/deploy_single_stack.yaml
          loop: "{{ hostvars['localhost']._stacks | reject('equalto', 'databases') | list }}"
          loop_control:
            loop_var: _current_stack
          vars:
            _test_mode: true
            patch_compose_networks: true
            _apps_vip: >-
              {% if test_vm_role is defined %}{{ ansible_default_ipv4.address.rsplit('.', 1)[0] }}.{{ docker_test_vip_offsets['apps'] }}{% else %}{{ vault_apps_vip }}{% endif %}

        # ===== HEALTH CHECK =====
        - name: Verify container health
          include_tasks: tasks/verify_docker_health.yaml
          vars:
            _test_mode: true

        # ===== NETWORK VERIFICATION =====
        - name: Verify Docker network connectivity
          include_tasks: tasks/verify_docker_network.yaml

        # ===== NETWORK ISOLATION VERIFICATION =====
        - name: Verify test VLAN isolation from production
          include_tasks: tasks/verify_network_isolation.yaml
          vars:
            _vm: "{{ hostvars['localhost']._vm }}"

        # ===== VIP VERIFICATION =====
        - name: Verify VIP is active
          include_tasks: tasks/verify_vip.yaml

        - name: Record success detail
          ansible.builtin.set_fact:
            _restore_test_detail: >-
              {{ restore_app | default('full') }} restore verified
              — {{ hostvars['localhost']._stacks | join(', ') }} stack(s)

      rescue:
        - name: Set restore test failed flag
          ansible.builtin.set_fact:
            _restore_test_failed: true
            _restore_test_detail: "{{ ansible_failed_result.msg | default('check Semaphore logs') }}{{ (' | ' + ansible_failed_result.stdout | trim) if ansible_failed_result.stdout | default('') | trim | length > 0 else '' }}"

      always:
        - name: Clean up temp archive
          ansible.builtin.file:
            path: "/tmp/restore_inplace.tar.gz"
            state: absent

        - name: Send Discord notification
          include_tasks: tasks/notify.yaml
          vars:
            discord_name: "{{ maintenance_name }}"
            discord_operation: "Restore Test"
            discord_status: "{{ 'failed' if _restore_test_failed else 'successful' }}"
            discord_detail: >-
              {{ source_host }}{{ ' (' + restore_app + ')' if restore_app | default('') | length > 0 else '' }}
            discord_color: "{{ discord_color_failure if _restore_test_failed else discord_color_success }}"
            discord_url: "{{ semaphore_ext_url }}"
            discord_author: "{{ controller_fqdn }}"
            discord_fields:
              - name: "Source Host"
                value: "{{ source_host }}"
                inline: true
              - name: "Test VM"
                value: "{{ hostvars['localhost']._vm.vm_name }}"
                inline: true
              - name: "Stacks"
                value: "{{ hostvars['localhost']._stacks | join(', ') }}"
              - name: "Detail"
                value: "{{ _restore_test_detail }}"

        - name: Log test restore to MariaDB
          include_tasks: tasks/log_mariadb.yaml
          vars:
            log_table: maintenance
            log_application: "{{ maintenance_name }}"
            log_hostname: "{{ controller_fqdn }}"
            log_type: "{{ maintenance_type }}"
            log_subtype: "{{ maintenance_subtype }}"
            log_status: "{{ 'failed' if _restore_test_failed else 'success' }}"

# ═══════════════════════════════════════════════════════════════════
# Play 5 — Revert to clean state (skipped in DR mode)
# ═══════════════════════════════════════════════════════════════════
- name: Revert test VM to clean state
  hosts: localhost
  gather_facts: false
  vars_files:
    - vars/secrets.yaml
    - vars/vm_definitions.yaml

  tasks:
    - name: Skip revert in DR mode
      ansible.builtin.debug:
        msg: "DR mode — keeping restored state on {{ vm_definitions[vm_name].vm_name }}"
      when: dr_mode | default('') == 'yes'

    - name: Revert VM to pre-test snapshot
      block:
        - name: Stop VM
          community.general.proxmox_kvm:
            api_host: "{{ pve_api_host }}"
            api_user: "{{ pve_api_user }}"
            api_token_id: "{{ pve_api_token_id }}"
            api_token_secret: "{{ pve_api_token_secret }}"
            node: "{{ _vm_actual_node }}"
            vmid: "{{ vm_definitions[vm_name].vm_id }}"
            state: stopped
            force: true
          no_log: "{{ not (debug_no_log | default(false) | bool) and (ansible_verbosity | default(0) | int < 3) }}"
          ignore_errors: true

        - name: Revert to pre-test snapshot
          ansible.builtin.uri:
            url: "https://{{ pve_api_host }}:8006/api2/json/nodes/{{ _vm_actual_node }}/qemu/{{ vm_definitions[vm_name].vm_id }}/snapshot/pre-test-restore/rollback"
            method: POST
            headers:
              Authorization: "PVEAPIToken={{ pve_api_user }}!{{ pve_api_token_id }}={{ pve_api_token_secret }}"
            validate_certs: false
          no_log: "{{ not (debug_no_log | default(false) | bool) and (ansible_verbosity | default(0) | int < 3) }}"

        - name: Wait for rollback to complete
          ansible.builtin.pause:
            seconds: 20

        - name: Delete pre-test snapshot
          ansible.builtin.uri:
            url: "https://{{ pve_api_host }}:8006/api2/json/nodes/{{ _vm_actual_node }}/qemu/{{ vm_definitions[vm_name].vm_id }}/snapshot/pre-test-restore"
            method: DELETE
            headers:
              Authorization: "PVEAPIToken={{ pve_api_user }}!{{ pve_api_token_id }}={{ pve_api_token_secret }}"
            validate_certs: false
          no_log: "{{ not (debug_no_log | default(false) | bool) and (ansible_verbosity | default(0) | int < 3) }}"
      when: not (dr_mode | default('') == 'yes')

    - name: Fail if test restore failed
      ansible.builtin.fail:
        msg: "Test restore failed: {{ hostvars[vm_definitions[vm_name].vm_hostname]._restore_test_detail | default('check Semaphore logs') }}"
      when: hostvars[vm_definitions[vm_name].vm_hostname]._restore_test_failed | default(false)
