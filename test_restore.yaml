---
# Automated restore testing on a disposable VM.
# Builds VM if needed, restores source host's appdata, deploys stacks,
# verifies container health, and reverts to clean state.
# Also serves as a DR recovery tool via -e dr_mode=yes.
#
# Usage:
#   # Test controller's full stack (local /opt)
#   ansible-playbook test_restore.yaml -e vm_name=test-vm -e source_host=<controller-fqdn>
#
#   # Test restore on CephFS-backed /opt (auto-creates CephFS dir + mounts during bootstrap)
#   ansible-playbook test_restore.yaml -e vm_name=cephfs-migrate-test -e source_host=<role-fqdn>
#
#   # Restore from old hostname backups after host rename (backup_source overrides archive path)
#   ansible-playbook test_restore.yaml -e vm_name=cephfs-migrate-test -e source_host=apps.example.com -e backup_source=odyssey.example.com
#
#   # Test single app restore
#   ansible-playbook test_restore.yaml -e vm_name=test-vm -e source_host=<controller-fqdn> -e restore_app=authentik
#
#   # Test single stack deploy
#   ansible-playbook test_restore.yaml -e vm_name=test-vm -e source_host=<source-fqdn> -e deploy_stack=media
#
#   # DR recovery (keeps restored state, no revert)
#   ansible-playbook test_restore.yaml -e vm_name=test-vm -e source_host=<controller-fqdn> -e dr_mode=yes
#
# Required extra vars:
#   vm_name      — ephemeral VM key from vm_definitions (use "test-vm" for local /opt, or
#                  "cephfs-migrate-test" for CephFS-backed /opt). Do NOT use permanent VM keys.
#   source_host  — inventory_hostname of source host in stack_assignments
#
# Optional extra vars:
#   backup_source — hostname whose backup directory to restore from (defaults to source_host).
#                   Useful when stack_assignments keys differ from the backup directory names
#                   (e.g. after renaming hosts: -e source_host=apps.example.com -e backup_source=odyssey.example.com).
#
# VM lifecycle (provision_vm.yaml is idempotent):
#   - If the VMID doesn't exist, the VM is provisioned from the cloud-init template
#   - If the VMID already exists (e.g. from a prior partial run), clone is skipped and
#     provisioning resumes from configure/start — no manual cleanup needed
#   - Node resolution uses the cluster resources API — VIP-safe regardless of which
#     PVE node is currently MASTER
#   - After restore: snapshot is reverted, VM stays running and ready for next test
#   - In dr_mode=yes: no revert — VM keeps the restored state for real DR recovery
#
# Optional extra vars:
#   vm_index=N    — test-vm slot 0..9; auto-detected (lowest non-running slot) if omitted
#   restore_app   — single app name to selectively extract from archive
#   deploy_stack  — single stack to deploy
#   dr_mode=yes   — DR recovery mode (skip snapshot/revert, keep state)

# ═══════════════════════════════════════════════════════════════════
# Play 1 — Prepare: Validate, find backup, build VM if needed, snapshot
# ═══════════════════════════════════════════════════════════════════
- name: Prepare test restore
  hosts: localhost
  gather_facts: true
  gather_subset: ['!all', 'date_time']
  vars_files:
    - vars/secrets.yaml
    - vars/proxmox.yaml
    - vars/docker_stacks.yaml
    - vars/vm_definitions.yaml
    - vars/semaphore_check.yaml
  vars:
    maintenance_name: "Docker"
    maintenance_type: "Servers"
    maintenance_subtype: "Test Restore"

  pre_tasks:
    - name: Assert vm_name exists in vm_definitions
      ansible.builtin.assert:
        that:
          - vm_name is defined
          - vm_name in vm_definitions
        fail_msg: >-
          vm_name '{{ vm_name | default('undefined') }}' not found in vm_definitions.
          Valid names: {{ vm_definitions.keys() | list | join(', ') }}

    - name: Assert source_host exists in stack_assignments
      ansible.builtin.assert:
        that:
          - source_host is defined
          - source_host in stack_assignments
        fail_msg: >-
          source_host '{{ source_host | default('undefined') }}' not found in stack_assignments.
          Valid hosts: {{ stack_assignments.keys() | list | join(', ') }}

    - name: Assert MariaDB logging database is reachable
      include_tasks: tasks/assert_db_connectivity.yaml

    - name: Log playbook run context to MariaDB
      include_tasks: tasks/log_run_context.yaml
      vars:
        log_playbook: "test_restore.yaml"
        log_hostname: "{{ controller_fqdn }}"
        log_run_vars: "{{ {'vm_name': vm_name | default('')} | to_json }}"

  tasks:
    - name: Auto-detect free vm_index for test-vm pool
      include_tasks: tasks/resolve_test_vm_index.yaml
      when: vm_name in ['test-vm', 'cephfs-migrate-test']

    - name: Resolve VM and stack configuration
      ansible.builtin.set_fact:
        _vm: "{{ vm_definitions[vm_name] }}"
        _backup_source: "{{ backup_source | default(source_host) }}"
        _stacks: >-
          {{ [deploy_stack] if deploy_stack | default('') | length > 0
             else stack_assignments[source_host] }}

    # ===== AUTO-CREATE CEPHFS DIR (when vm has cephfs_host_dir) =====
    - name: Add PVE host to in-memory inventory (for CephFS dir creation)
      ansible.builtin.add_host:
        name: pve_builder
        ansible_host: "{{ pve_api_host }}"
        ansible_user: ansible
      when: _vm.cephfs_host_dir is defined

    - name: Ensure CephFS host directory exists on CephFS root
      ansible.builtin.shell: |
        set -e
        MOUNT_DIR=$(mktemp -d)
        ADMIN_KEY=$(ceph auth print-key client.admin)
        mount -t ceph {{ vault_ceph_mons }}:/ "$MOUNT_DIR" \
          -o "name=admin,secret=${ADMIN_KEY}"
        if [ -d "$MOUNT_DIR/{{ _vm.cephfs_host_dir }}" ]; then
          echo "exists"
        else
          mkdir "$MOUNT_DIR/{{ _vm.cephfs_host_dir }}"
          echo "created"
        fi
        umount "$MOUNT_DIR"
        rmdir "$MOUNT_DIR"
      args:
        executable: /bin/bash
      delegate_to: pve_builder
      become: true
      register: _cephfs_dir_result
      changed_when: "'created' in _cephfs_dir_result.stdout"
      no_log: "{{ not (debug_no_log | default(false) | bool) and (ansible_verbosity | default(0) | int < 3) }}"
      when: _vm.cephfs_host_dir is defined

    # ===== FIND BACKUP ARCHIVES =====
    # Requires the container user to have read access to the /backup/ bind
    # mount (e.g. via group_add: 100 for the users group on unRAID).
    - name: Find per-stack backup archives for source host
      ansible.builtin.shell: >
        ls -t {{ backup_base_dir }}/{{ _backup_source }}/backup_{{ item }}_*.tar.gz 2>/dev/null | head -1
      loop: "{{ _stacks }}"
      register: _per_stack_archives
      become: false
      changed_when: false
      check_mode: false

    - name: Set per-stack archive list
      ansible.builtin.set_fact:
        _archive_files: "{{ _per_stack_archives.results | selectattr('stdout', 'ne', '') | map(attribute='stdout') | list }}"

    - name: Fall back to monolithic archive
      ansible.builtin.shell: >
        ls -t {{ backup_base_dir }}/{{ _backup_source }}/backup_*.tar.gz 2>/dev/null | head -1
      register: _monolithic_archive
      become: false
      changed_when: false
      check_mode: false
      when: _archive_files | length == 0

    - name: Use monolithic archive as fallback
      ansible.builtin.set_fact:
        _archive_files: "{{ [_monolithic_archive.stdout] }}"
      when:
        - _archive_files | length == 0
        - _monolithic_archive.stdout | default('') | length > 0

    - name: Assert backup archives exist
      ansible.builtin.assert:
        that: _archive_files | length > 0
        fail_msg: "No backup archives found for {{ _backup_source }}"

    - name: Verify archive integrity
      ansible.builtin.shell: gunzip -t "{{ item }}"
      loop: "{{ _archive_files }}"
      become: false
      changed_when: false
      check_mode: false

    # ===== CHECK IF VM EXISTS =====
    # Use cluster resources API (VIP-safe — discovers the actual node regardless of which PVE node is MASTER)
    - name: Check if VM exists in cluster
      ansible.builtin.uri:
        url: "https://{{ pve_api_host }}:8006/api2/json/cluster/resources?type=vm"
        method: GET
        headers:
          Authorization: "PVEAPIToken={{ pve_api_user }}!{{ pve_api_token_id }}={{ pve_api_token_secret }}"
        validate_certs: false
      register: _cluster_vms
      no_log: "{{ not (debug_no_log | default(false) | bool) and (ansible_verbosity | default(0) | int < 3) }}"

    - name: Set VM existence and node facts
      ansible.builtin.set_fact:
        _vm_exists: "{{ _cluster_vms.json.data | selectattr('vmid', 'equalto', _vm.vm_id | int) | list | length > 0 }}"
        _vm_actual_node: >-
          {{ (_cluster_vms.json.data | selectattr('vmid', 'equalto', _vm.vm_id | int) | list | first).node
             if (_cluster_vms.json.data | selectattr('vmid', 'equalto', _vm.vm_id | int) | list | length > 0)
             else _vm.pve_target_node }}
        _vm_cluster_status: >-
          {{ (_cluster_vms.json.data | selectattr('vmid', 'equalto', _vm.vm_id | int) | list | first).status
             if (_cluster_vms.json.data | selectattr('vmid', 'equalto', _vm.vm_id | int) | list | length > 0)
             else 'unknown' }}

    # ===== BUILD VM IF NEEDED =====
    - name: Provision VM on Proxmox
      include_tasks: tasks/provision_vm.yaml
      vars:
        _provision_target_group: test_target
      when: not _vm_exists

    - name: Add existing VM to inventory
      ansible.builtin.add_host:
        name: "{{ _vm.vm_hostname }}"
        ansible_host: "{{ _vm.vm_ip }}"
        ansible_user: "{{ vm_user }}"
        groups: test_target
        _needs_bootstrap: false
      when: _vm_exists

    - name: Start existing VM if stopped
      ansible.builtin.uri:
        url: "https://{{ pve_api_host }}:8006/api2/json/nodes/{{ _vm_actual_node }}/qemu/{{ _vm.vm_id }}/status/start"
        method: POST
        headers:
          Authorization: "PVEAPIToken={{ pve_api_user }}!{{ pve_api_token_id }}={{ pve_api_token_secret }}"
        validate_certs: false
        status_code: [200, 500]
      no_log: "{{ not (debug_no_log | default(false) | bool) and (ansible_verbosity | default(0) | int < 3) }}"
      when:
        - _vm_exists
        - _vm_cluster_status == 'stopped'

    - name: Wait for SSH on existing VM
      ansible.builtin.wait_for:
        host: "{{ _vm.vm_ip }}"
        port: 22
        delay: 10
        timeout: 300
      when:
        - _vm_exists
        - _vm_cluster_status == 'stopped'

# ═══════════════════════════════════════════════════════════════════
# Play 2 — Bootstrap (new VM or Docker missing)
# ═══════════════════════════════════════════════════════════════════
- name: Bootstrap test VM
  hosts: test_target
  become: true
  gather_facts: false
  vars_files:
    - vars/secrets.yaml
    - vars/vm_definitions.yaml
    - vars/docker_vips.yaml

  tasks:
    - name: Wait for system boot to complete
      ansible.builtin.wait_for_connection:
        delay: 5
        timeout: 300

    - name: Gather facts
      ansible.builtin.setup:

    - name: Check if Docker is installed
      ansible.builtin.command: docker --version
      register: _docker_check
      failed_when: false
      changed_when: false
      become: false

    - name: Bootstrap Ubuntu with Docker and security hardening
      include_tasks: tasks/bootstrap_vm.yaml
      vars:
        _vm: "{{ hostvars['localhost']._vm }}"
      when: hostvars[inventory_hostname]._needs_bootstrap | default(false) or _docker_check.rc != 0

# ═══════════════════════════════════════════════════════════════════
# Play 3 — Snapshot clean post-bootstrap state for revert
# ═══════════════════════════════════════════════════════════════════
- name: Create pre-test snapshot
  hosts: localhost
  gather_facts: false
  vars_files:
    - vars/secrets.yaml
    - vars/vm_definitions.yaml

  tasks:
    - name: Get existing snapshots
      ansible.builtin.uri:
        url: "https://{{ pve_api_host }}:8006/api2/json/nodes/{{ _vm_actual_node }}/qemu/{{ vm_definitions[vm_name].vm_id }}/snapshot"
        method: GET
        headers:
          Authorization: "PVEAPIToken={{ pve_api_user }}!{{ pve_api_token_id }}={{ pve_api_token_secret }}"
        validate_certs: false
      no_log: "{{ not (debug_no_log | default(false) | bool) and (ansible_verbosity | default(0) | int < 3) }}"
      register: _vm_snapshots
      when: not (dr_mode | default('') == 'yes')

    - name: Delete existing pre-test snapshot if present
      ansible.builtin.uri:
        url: "https://{{ pve_api_host }}:8006/api2/json/nodes/{{ _vm_actual_node }}/qemu/{{ vm_definitions[vm_name].vm_id }}/snapshot/pre-test-restore"
        method: DELETE
        headers:
          Authorization: "PVEAPIToken={{ pve_api_user }}!{{ pve_api_token_id }}={{ pve_api_token_secret }}"
        validate_certs: false
      no_log: "{{ not (debug_no_log | default(false) | bool) and (ansible_verbosity | default(0) | int < 3) }}"
      when:
        - not (dr_mode | default('') == 'yes')
        - _vm_snapshots.json.data | selectattr('name', 'equalto', 'pre-test-restore') | list | length > 0

    - name: Wait for VM lock to clear after snapshot delete
      ansible.builtin.uri:
        url: "https://{{ pve_api_host }}:8006/api2/json/nodes/{{ _vm_actual_node }}/qemu/{{ vm_definitions[vm_name].vm_id }}/status/current"
        method: GET
        headers:
          Authorization: "PVEAPIToken={{ pve_api_user }}!{{ pve_api_token_id }}={{ pve_api_token_secret }}"
        validate_certs: false
      register: _vm_lock_status
      until: _vm_lock_status.json.data.lock is not defined
      retries: 20
      delay: 3
      no_log: "{{ not (debug_no_log | default(false) | bool) and (ansible_verbosity | default(0) | int < 3) }}"
      when:
        - not (dr_mode | default('') == 'yes')
        - _vm_snapshots.json.data | selectattr('name', 'equalto', 'pre-test-restore') | list | length > 0

    - name: Create pre-test snapshot (post-bootstrap clean state)
      ansible.builtin.uri:
        url: "https://{{ pve_api_host }}:8006/api2/json/nodes/{{ _vm_actual_node }}/qemu/{{ vm_definitions[vm_name].vm_id }}/snapshot"
        method: POST
        headers:
          Authorization: "PVEAPIToken={{ pve_api_user }}!{{ pve_api_token_id }}={{ pve_api_token_secret }}"
        body_format: form-urlencoded
        body:
          snapname: pre-test-restore
          vmstate: 0
        validate_certs: false
      no_log: "{{ not (debug_no_log | default(false) | bool) and (ansible_verbosity | default(0) | int < 3) }}"
      when: not (dr_mode | default('') == 'yes')

# ═══════════════════════════════════════════════════════════════════
# Play 4 — Deploy, Restore, and Health Check
# ═══════════════════════════════════════════════════════════════════
- name: Test restore on VM
  hosts: test_target
  become: true
  gather_facts: true
  gather_subset: ['!all', 'date_time']
  vars_files:
    - vars/secrets.yaml
    - vars/docker_stacks.yaml
    - vars/vm_definitions.yaml
    - vars/semaphore_check.yaml
  vars:
    maintenance_name: "Docker"
    maintenance_type: "Servers"
    maintenance_subtype: "Test Restore"
    backup_tmp_dir: "/tmp"

  tasks:
    - name: Initialize restore state
      ansible.builtin.set_fact:
        _restore_test_failed: false
        _restore_test_detail: ""

    - name: Clean CephFS appdata for fresh test
      ansible.builtin.shell: |
        find /opt -mindepth 1 -maxdepth 1 -exec rm -rf {} +
      when:
        - hostvars['localhost']._vm.cephfs_host_dir is defined
        - _test_mode | default(false)

    - name: Ensure shared Docker network exists
      community.docker.docker_network:
        name: homelab
        state: present
      become: true

    - block:
        # ===== EXTRACT APPDATA FROM BACKUP =====
        - name: Ensure backup_tmp_dir exists on test VM
          ansible.builtin.file:
            path: "{{ backup_tmp_dir }}"
            state: directory
            mode: '0755'
          become: true

        - name: Compute selective extract path
          ansible.builtin.set_fact:
            _extract_path: "{{ (src_raw_files[0] | regex_replace('^/', '')) + '/' + restore_app }}"
          when: restore_app | default('') | length > 0

        - name: Restore appdata from each archive
          include_tasks: tasks/restore_appdata.yaml
          loop: "{{ hostvars['localhost']._archive_files }}"
          loop_control:
            loop_var: _current_archive
          vars:
            _restore_archive_path: "{{ _current_archive }}"
            _restore_mode: inplace
            _restore_extract_path: "{{ _extract_path | default('') }}"
            _restore_app_name: "{{ restore_app | default('') }}"

        # ===== DEPLOY STACKS =====
        - name: "Deploy stack — {{ _current_stack }}"
          include_tasks: tasks/deploy_single_stack.yaml
          loop: "{{ hostvars['localhost']._stacks }}"
          loop_control:
            loop_var: _current_stack
          vars:
            _test_mode: true

        # ===== HEALTH CHECK =====
        - name: Verify container health
          include_tasks: tasks/verify_docker_health.yaml
          vars:
            _test_mode: true

        - name: Record success detail
          ansible.builtin.set_fact:
            _restore_test_detail: >-
              {{ restore_app | default('full') }} restore verified
              — {{ hostvars['localhost']._stacks | join(', ') }} stack(s)

      rescue:
        - name: Set restore test failed flag
          ansible.builtin.set_fact:
            _restore_test_failed: true
            _restore_test_detail: "{{ ansible_failed_result.msg | default('check Semaphore logs') }}{{ (' | ' + ansible_failed_result.stdout | trim) if ansible_failed_result.stdout | default('') | trim | length > 0 else '' }}"

      always:
        - name: Clean up temp archive
          ansible.builtin.file:
            path: "/tmp/restore_inplace.tar.gz"
            state: absent

        - name: Send Discord notification
          include_tasks: tasks/notify.yaml
          vars:
            discord_name: "{{ maintenance_name }}"
            discord_operation: "Restore Test"
            discord_status: "{{ 'failed' if _restore_test_failed else 'successful' }}"
            discord_detail: >-
              {{ source_host }}{{ ' (' + restore_app + ')' if restore_app | default('') | length > 0 else '' }}
            discord_color: "{{ discord_color_failure if _restore_test_failed else discord_color_success }}"
            discord_url: "{{ semaphore_ext_url }}"
            discord_author: "{{ controller_fqdn }}"
            discord_fields:
              - name: "Source Host"
                value: "{{ source_host }}"
                inline: true
              - name: "Test VM"
                value: "{{ hostvars['localhost']._vm.vm_name }}"
                inline: true
              - name: "Stacks"
                value: "{{ hostvars['localhost']._stacks | join(', ') }}"
              - name: "Detail"
                value: "{{ _restore_test_detail }}"

        - name: Log test restore to MariaDB
          include_tasks: tasks/log_mariadb.yaml
          vars:
            log_table: maintenance
            log_application: "{{ maintenance_name }}"
            log_hostname: "{{ controller_fqdn }}"
            log_type: "{{ maintenance_type }}"
            log_subtype: "{{ maintenance_subtype }}"
            log_status: "{{ 'failed' if _restore_test_failed else 'success' }}"

# ═══════════════════════════════════════════════════════════════════
# Play 5 — Revert to clean state (skipped in DR mode)
# ═══════════════════════════════════════════════════════════════════
- name: Revert test VM to clean state
  hosts: localhost
  gather_facts: false
  vars_files:
    - vars/secrets.yaml
    - vars/vm_definitions.yaml

  tasks:
    - name: Skip revert in DR mode
      ansible.builtin.debug:
        msg: "DR mode — keeping restored state on {{ vm_definitions[vm_name].vm_name }}"
      when: dr_mode | default('') == 'yes'

    - name: Revert VM to pre-test snapshot
      block:
        - name: Stop VM
          community.general.proxmox_kvm:
            api_host: "{{ pve_api_host }}"
            api_user: "{{ pve_api_user }}"
            api_token_id: "{{ pve_api_token_id }}"
            api_token_secret: "{{ pve_api_token_secret }}"
            node: "{{ _vm_actual_node }}"
            vmid: "{{ vm_definitions[vm_name].vm_id }}"
            state: stopped
            force: true
          no_log: "{{ not (debug_no_log | default(false) | bool) and (ansible_verbosity | default(0) | int < 3) }}"
          ignore_errors: true

        - name: Revert to pre-test snapshot
          ansible.builtin.uri:
            url: "https://{{ pve_api_host }}:8006/api2/json/nodes/{{ _vm_actual_node }}/qemu/{{ vm_definitions[vm_name].vm_id }}/snapshot/pre-test-restore/rollback"
            method: POST
            headers:
              Authorization: "PVEAPIToken={{ pve_api_user }}!{{ pve_api_token_id }}={{ pve_api_token_secret }}"
            validate_certs: false
          no_log: "{{ not (debug_no_log | default(false) | bool) and (ansible_verbosity | default(0) | int < 3) }}"

        - name: Wait for rollback to complete
          ansible.builtin.pause:
            seconds: 20

        - name: Delete pre-test snapshot
          ansible.builtin.uri:
            url: "https://{{ pve_api_host }}:8006/api2/json/nodes/{{ _vm_actual_node }}/qemu/{{ vm_definitions[vm_name].vm_id }}/snapshot/pre-test-restore"
            method: DELETE
            headers:
              Authorization: "PVEAPIToken={{ pve_api_user }}!{{ pve_api_token_id }}={{ pve_api_token_secret }}"
            validate_certs: false
          no_log: "{{ not (debug_no_log | default(false) | bool) and (ansible_verbosity | default(0) | int < 3) }}"
      when: not (dr_mode | default('') == 'yes')

    - name: Fail if test restore failed
      ansible.builtin.fail:
        msg: "Test restore failed: {{ hostvars[vm_definitions[vm_name].vm_hostname]._restore_test_detail | default('check Semaphore logs') }}"
      when: hostvars[vm_definitions[vm_name].vm_hostname]._restore_test_failed | default(false)
