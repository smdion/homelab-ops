---
# Back up host configurations and appdata.
# Docker stacks: per-stack archives (stop one stack at a time, minimize downtime).
# Other hosts: monolithic archive (stop Docker, archive all paths, restart).
# Sends notification + logs each backup to MariaDB.
#
# Scope selectors (docker_stacks only):
#   stack=<name>  — back up a single stack (auto-resolves host)
#   app=<name>    — back up a single app's stack (resolves via app_definitions)
#   role=<name>   — back up all stacks in a role (auto-resolves host)
#
# Combined mode (docker_stacks / docker_run only):
#   with_databases=yes — also dump MariaDB + Postgres after appdata backup
#   DB backups always run ALL databases (no role/stack/app scoping).
#   Replaces the old backup_stacks.yaml wrapper.
#
# Usage:
#   ansible-playbook backup_hosts.yaml -e hosts_variable=proxmox
#   ansible-playbook backup_hosts.yaml -e hosts_variable=docker_stacks
#   ansible-playbook backup_hosts.yaml -e hosts_variable=docker_stacks -e stack=auth
#   ansible-playbook backup_hosts.yaml -e hosts_variable=docker_stacks -e app=authentik
#   ansible-playbook backup_hosts.yaml -e hosts_variable=docker_stacks -e role=core
#   ansible-playbook backup_hosts.yaml -e hosts_variable=docker_stacks -e with_databases=yes
#   ansible-playbook backup_hosts.yaml -e hosts_variable=docker_stacks -e with_databases=yes -e role=core

- name: Back up host configurations and appdata
  gather_facts: true
  gather_subset: ['!all', 'date_time']
  serial: 1
  vars_files:
    - vars/secrets.yaml
    - vars/vm_definitions.yaml
    - vars/host_definitions.yaml
    - vars/app_definitions.yaml
    - vars/{{ config_file }}.yaml
  vars:
    config_file: "{{ hosts_variable }}"
  hosts: "{{ hosts_variable }}"

  pre_tasks:
    - name: Resolve scope (role injection + stack/role filtering)
      include_tasks: tasks/resolve_scope.yaml

    - name: Put PiKVM device in RW mode (for backup)
      raw: rw
      when:
        - inventory_hostname in groups["pikvm"]
        - not ansible_check_mode

    - name: Assert sufficient disk space on remote backup dir
      include_tasks: tasks/assert_disk_space.yaml
      vars:
        assert_disk_path: "{{ backup_tmp_dir }}"
        assert_disk_min_gb: "{{ backup_assert_disk_min_gb | default(2) }}"

    - name: Assert sufficient disk space on controller
      include_tasks: tasks/assert_disk_space.yaml
      vars:
        assert_disk_path: "{{ backup_base_dir }}"
        assert_disk_min_gb: "{{ controller_assert_disk_min_gb | default(2) }}"
        assert_disk_delegate_to: localhost
        assert_disk_become: false

    - name: Run standard pre-flight assertions for backup_hosts
      include_tasks: tasks/pre_task_assertions.yaml
      vars:
        pre_assert_config_file: true
        pre_playbook: "backup_hosts.yaml"
        pre_run_vars: "{{ {'config_file': config_file | default('')} | to_json }}"

    - name: Assert DockerClient.php exists on unRAID
      ansible.builtin.stat:
        path: /usr/local/emhttp/plugins/dynamix.docker.manager/include/DockerClient.php
      register: _unraid_docker_client
      when:
        - inventory_hostname in groups["docker_run"] | default([])
        - inventory_hostname in groups["unraid"] | default([])

    - name: Fail if DockerClient.php missing on unRAID
      ansible.builtin.fail:
        msg: "unRAID DockerClient.php not found — Dynamix Docker Manager plugin may not be installed"
      when:
        - inventory_hostname in groups["docker_run"] | default([])
        - inventory_hostname in groups["unraid"] | default([])
        - not (_unraid_docker_client.stat.exists | default(false))

  tasks:
    - name: Set run-scoped temp directory (concurrency-safe)
      ansible.builtin.set_fact:
        backup_tmp_dir: "{{ backup_tmp_dir }}/run_{{ ansible_date_time.iso8601_basic_short }}"

    - name: Create run-scoped temp directory
      become: true
      ansible.builtin.file:
        state: directory
        path: "{{ backup_tmp_dir }}"

    - name: Find old Unifi backup files exceeding retention
      become: true
      ansible.builtin.find:
        paths: "{{ item }}"
        age: "{{ unifi_backup_retention }}"
        age_stamp: mtime
        recurse: false
      register: _old_backups
      loop: "{{ src_raw_files }}"
      when: inventory_hostname in groups["unifi_network"]

    - name: Delete old Unifi backup files exceeding retention
      become: true
      ansible.builtin.file:
        path: "{{ _found_file.path }}"
        state: absent
      loop: "{{ _old_backups.results | default([]) | map(attribute='files') | flatten }}"
      loop_control:
        loop_var: _found_file
      when: inventory_hostname in groups["unifi_network"]

    - name: Extract WireGuard VPS config
      become: true
      ansible.builtin.shell: >
        awk -v addr="{{ vps_address }}" '$0 ~ "\"address\": \"" addr "\"," {found=1; count=0} found && count<8 {gsub(/^[ \t]+/, "", $0); print; count++}'
        {{ unifi_state_file }} > {{ src_raw_files | first }}/{{ wg_config_file }}
      when: inventory_hostname in groups["unifi_network"]

    - name: Initialize backup state for {{ inventory_hostname }}
      ansible.builtin.set_fact:
        file_size: {stat: {size: 0}}
        backup_failed: false
        _stack_backup_results: []
        _amp_backup_results: []
        _original_backup_name: "{{ backup_name }}"
        _original_backup_url: "{{ backup_url }}"
        _target_stacks: >-
          {{ [stack] if stack is defined
             else backup_stack_order[inventory_hostname]
                  | default(stack_assignments[inventory_hostname] | default([]) | reverse | list) }}

    - name: "Report stack assignment diagnostics (debug)"
      ansible.builtin.debug:
        msg:
          _target_stacks: "{{ _target_stacks }}"
          stack_assignments_for_host: "{{ stack_assignments[inventory_hostname] | default('UNDEFINED') }}"
          backup_stack_order_for_host: "{{ backup_stack_order[inventory_hostname] | default('UNDEFINED') }}"
          host_roles_for_host: "{{ host_roles[inventory_hostname] | default('UNDEFINED') }}"
          host_roles_keys: "{{ host_roles | default({}) | dict2items | map(attribute='key') | list }}"
          stack_roles_keys: "{{ stack_roles | default({}) | dict2items | map(attribute='key') | list }}"
      when: inventory_hostname in groups["docker_stacks"] | default([])

    - block:
        # ===== PER-STACK BACKUP (docker_stacks hosts) =====
        - name: Back up per-stack archives for {{ inventory_hostname }}
          include_tasks: tasks/backup_single_stack.yaml
          loop: "{{ _target_stacks }}"
          loop_control:
            loop_var: _backup_stack
          when:
            - inventory_hostname in groups["docker_stacks"] | default([])
            - not ansible_check_mode

        - name: Set failed flag if per-stack backups failed
          ansible.builtin.set_fact:
            backup_failed: "{{ _stack_backup_results | selectattr('failed') | list | length > 0 }}"
          when: inventory_hostname in groups["docker_stacks"] | default([])

        # ===== MONOLITHIC BACKUP (non-docker_stacks hosts) =====
        # ===== CAPTURE IMAGE VERSIONS (before stop — containers must exist) =====
        - name: Capture image versions for monolithic Docker backup
          include_tasks: tasks/capture_image_versions.yaml
          vars:
            _versions_filter: ""
            _versions_label: "{{ inventory_hostname }}"
            _versions_dest: "{{ backup_base_dir }}/{{ inventory_hostname }}"
          when:
            - inventory_hostname not in groups["docker_stacks"] | default([])
            - inventory_hostname in groups["docker_run"] | default([])
            - config_file == 'docker_run'

        # ===== STOP DOCKER =====
        - include_tasks: tasks/docker_stop.yaml
          vars:
            _docker_exclude_containers: "{{ backup_exclude_containers | default([]) }}"
          when:
            - inventory_hostname not in groups["docker_stacks"] | default([])
            - inventory_hostname in groups["docker_run"] | default([])
            - config_file == 'docker_run'

        # ===== UNVR PROTECT BACKUP VIA API =====
        - name: Trigger UNVR backup
          ansible.builtin.uri:
            url: "https://{{ inventory_hostname }}{{ unifi_protect_api_backup_path }}"
            method: POST
            body_format: json
            body:
              cmd: "backup"
              days: "-1"
            validate_certs: false  # UNVR uses a self-signed cert; vendor API prevents proper TLS cert management
            headers:
              x-api-key: "{{ unvr_api_key }}"
            status_code: 200
          register: _unvr_backup
          delegate_to: localhost
          ignore_errors: true  # TODO: API endpoint 404 — silence until correct path is found (IMP-10)
          when:
            - inventory_hostname in groups["unifi_protect"]
            - not ansible_check_mode

        - name: Download UNVR backup file
          ansible.builtin.get_url:
            url: "https://{{ inventory_hostname }}{{ _unvr_backup.json.data[0].url }}"
            dest: "{{ unifi_protect_temp_file }}"
            mode: "0600"
            validate_certs: false  # UNVR uses a self-signed cert; vendor API prevents proper TLS cert management
            headers:
              x-api-key: "{{ unvr_api_key }}"
          delegate_to: localhost
          ignore_errors: true  # TODO: file retrieval broken — silence until fixed
          register: _unvr_download
          when:
            - inventory_hostname in groups["unifi_protect"]
            - not ansible_check_mode

        - name: Copy UNVR Protect backup to staging directory
          ansible.builtin.copy:
            src: "{{ unifi_protect_temp_file }}"
            dest: "{{ backup_tmp_file }}"
          when:
            - inventory_hostname in groups["unifi_protect"]
            - not (_unvr_download.failed | default(false))
            - not ansible_check_mode

        # ===== UNVR: camera inventory export =====
        - name: Export Unifi Protect camera inventory
          ansible.builtin.uri:
            url: "https://{{ inventory_hostname }}/proxy/protect/api/cameras"
            method: GET
            validate_certs: false  # UNVR uses a self-signed cert
            headers:
              x-api-key: "{{ unvr_api_key }}"
            status_code: 200
          register: _protect_cameras
          delegate_to: localhost
          ignore_errors: true
          when:
            - inventory_hostname in groups["unifi_protect"]
            - not ansible_check_mode

        - name: Save camera inventory to controller
          ansible.builtin.copy:
            content: "{{ _protect_cameras.json | to_nice_json }}"
            dest: "{{ backup_base_dir }}/{{ inventory_hostname }}/protect_camera_inventory_{{ ansible_date_time.date }}.json"
            mode: "0600"
          delegate_to: localhost
          become: false
          when:
            - inventory_hostname in groups["unifi_protect"]
            - _protect_cameras is defined
            - not (_protect_cameras.failed | default(false))
            - not ansible_check_mode

        # ===== Unifi Network: device inventory export =====
        - name: Export Unifi Network device inventory
          ansible.builtin.uri:
            url: "https://{{ inventory_hostname }}/proxy/network/api/s/default/stat/device"
            method: GET
            validate_certs: false  # UDM uses a self-signed cert
            headers:
              x-api-key: "{{ unifi_network_api_key }}"
            status_code: 200
          register: _unifi_devices
          delegate_to: localhost
          ignore_errors: true
          when:
            - inventory_hostname in groups["unifi_network"]
            - not ansible_check_mode

        - name: Save Unifi Network device inventory to controller
          ansible.builtin.copy:
            content: "{{ _unifi_devices.json | to_nice_json }}"
            dest: "{{ backup_base_dir }}/{{ inventory_hostname }}/unifi_device_inventory_{{ ansible_date_time.date }}.json"
            mode: "0600"
          delegate_to: localhost
          become: false
          when:
            - inventory_hostname in groups["unifi_network"]
            - _unifi_devices is defined
            - not (_unifi_devices.failed | default(false))
            - not ansible_check_mode

        # ===== AMP PER-INSTANCE BACKUP =====
        # Step 1: slurp instances.json (become: true to read root-protected home dir)
        # then copy to controller via delegate_to (avoids fetch + FUSE mount issue)
        - name: Slurp instances.json registry
          become: true
          ansible.builtin.slurp:
            src: "{{ amp_home }}/.ampdata/instances.json"
          register: _amp_instances_json
          ignore_errors: true  # non-fatal — per-instance backups must still run
          when:
            - inventory_hostname in groups["amp"] | default([])
            - not ansible_check_mode

        - name: Save instances.json registry to controller
          ansible.builtin.copy:
            content: "{{ _amp_instances_json.content | b64decode }}"
            dest: "{{ backup_base_dir }}/{{ inventory_hostname }}/amp_instances_{{ ansible_date_time.date }}.json"
            mode: "0600"
          delegate_to: localhost
          become: false
          when:
            - inventory_hostname in groups["amp"] | default([])
            - _amp_instances_json is defined
            - not (_amp_instances_json.failed | default(false))
            - not ansible_check_mode

        # Step 2: discover and back up each instance
        - name: Discover AMP instances on {{ inventory_hostname }}
          become: true
          ansible.builtin.find:
            paths: "{{ amp_home }}/.ampdata/instances"
            file_type: directory
            recurse: false
          register: _amp_instances_found
          when:
            - inventory_hostname in groups["amp"] | default([])
            - not ansible_check_mode

        - name: Set AMP instance list
          ansible.builtin.set_fact:
            _amp_instances: "{{ _amp_instances_found.files | map(attribute='path') | map('basename') | sort | list }}"
          when:
            - inventory_hostname in groups["amp"] | default([])
            - not ansible_check_mode

        - name: Save AMP instance inventory to controller
          ansible.builtin.copy:
            content: "{{ _amp_instances | default([]) | to_nice_json }}"
            dest: "{{ backup_base_dir }}/{{ inventory_hostname }}/amp_instance_inventory_{{ ansible_date_time.date }}.json"
            mode: "0600"
          delegate_to: localhost
          become: false
          when:
            - inventory_hostname in groups["amp"] | default([])
            - _amp_instances is defined
            - not ansible_check_mode

        - name: Back up AMP instances on {{ inventory_hostname }}
          include_tasks: tasks/backup_single_amp_instance.yaml
          loop: "{{ _amp_instances | default([]) }}"
          loop_control:
            loop_var: _amp_instance
          when:
            - inventory_hostname in groups["amp"] | default([])
            - not ansible_check_mode
            - amp_instance_filter is not defined or _amp_instance == amp_instance_filter

        - name: Set failed flag if AMP instance backups failed
          ansible.builtin.set_fact:
            backup_failed: "{{ _amp_backup_results | selectattr('failed') | list | length > 0 }}"
          when: inventory_hostname in groups["amp"] | default([])

        # ===== CREATE BACKUP (non-docker_stacks, non-UNVR, non-AMP hosts) =====
        - name: Filter backup paths to only existing directories
          become: true
          ansible.builtin.stat:
            path: "{{ item }}"
          loop: "{{ src_raw_files }}"
          register: _backup_paths_stat
          when:
            - inventory_hostname not in groups["docker_stacks"] | default([])
            - inventory_hostname not in groups["unifi_protect"]
            - inventory_hostname not in groups["amp"] | default([])

        - name: Set validated backup paths
          ansible.builtin.set_fact:
            _validated_backup_paths: >-
              {{ _backup_paths_stat.results | default([])
                 | selectattr('stat', 'defined')
                 | selectattr('stat.exists')
                 | map(attribute='item') | list }}
          when:
            - inventory_hostname not in groups["docker_stacks"] | default([])
            - inventory_hostname not in groups["unifi_protect"]
            - inventory_hostname not in groups["amp"] | default([])

        # When exclude dirs are defined, convert directory paths to globs (e.g. /opt → /opt/*)
        # so community.general.archive expands them to individual items that exclude_path can match.
        - name: Convert paths to globs for exclusion support
          ansible.builtin.set_fact:
            _archive_paths: >-
              {{ (_validated_backup_paths | default(src_raw_files))
                 | map('regex_replace', '/?$', '/*') | list }}
          when:
            - inventory_hostname not in groups["docker_stacks"] | default([])
            - inventory_hostname not in groups["unifi_protect"]
            - inventory_hostname not in groups["amp"] | default([])
            - backup_exclude_dirs | default([]) | length > 0

        # === unRAID: snapshot disk assignments to boot config (included in /boot archive) ===
        - name: Snapshot unRAID disk assignments to boot config
          ansible.builtin.copy:
            src: /var/local/emhttp/disks.ini
            dest: /boot/config/DISK_ASSIGNMENTS.ini
            remote_src: true
            mode: "0644"
          become: true
          when:
            - inventory_hostname in groups['unraid'] | default([])
            - config_file == 'unraid_os'
            - not ansible_check_mode

        # === unRAID: file inventory of all array shares (monthly — pass -e run_tree_index=yes) ===
        - name: Assert find command is available (tree index)
          ansible.builtin.shell: command -v find
          changed_when: false
          register: _find_check
          failed_when: _find_check.rc != 0
          check_mode: false
          when:
            - inventory_hostname in groups['unraid'] | default([])
            - run_tree_index | default(false) | bool

        - name: Generate unRAID file inventory of all array shares
          ansible.builtin.shell: |
            SAVEPATH="/mnt/user/Backup/{{ inventory_hostname }}/tree/array"
            for f in /mnt/user/*/; do
              share=$(basename "$f")
              mkdir -p "$SAVEPATH/$share"
              find "$f" | sort > "$SAVEPATH/$share/$(date +%Y%m%d).txt"
            done
          args:
            executable: /bin/bash
          changed_when: true
          when:
            - inventory_hostname in groups['unraid'] | default([])
            - run_tree_index | default(false) | bool
            - not ansible_check_mode

        # === PBS: export job and datastore configs into /etc so they're included in the archive ===
        - name: Create PBS DR export directory for config backup
          become: true
          ansible.builtin.file:
            path: /etc/proxmox-backup/dr-export
            state: directory
            mode: "0700"
          when:
            - inventory_hostname in groups['pbs'] | default([])
            - not ansible_check_mode

        - name: Export PBS job and datastore configurations
          become: true
          ansible.builtin.shell: |
            for job_type in sync-job backup-job prune-job verify-job; do
              proxmox-backup-manager ${job_type} list --output-format json \
                > /etc/proxmox-backup/dr-export/${job_type}-list.json 2>/dev/null || true
            done
            proxmox-backup-manager datastore list --output-format json \
              > /etc/proxmox-backup/dr-export/datastore-list.json 2>/dev/null || true
          args:
            executable: /bin/bash
          changed_when: true
          when:
            - inventory_hostname in groups['pbs'] | default([])
            - not ansible_check_mode

        - name: Create compressed backup archive for {{ inventory_hostname }}
          become: true
          ansible.builtin.shell: |
            {{ _gz_detect }}
            tar -I "$_gz -1" -cf "{{ backup_tmp_file }}" \
              {% for excl in (backup_exclude_dirs | default([])) %}
              --exclude='{{ excl }}' \
              {% endfor %}
              -C / \
              {{ (_archive_paths | default(_validated_backup_paths) | default(src_raw_files)) | map('regex_replace', '^/', '') | join(' ') }}
          timeout: 3600
          when:
            - inventory_hostname not in groups["docker_stacks"] | default([])
            - inventory_hostname not in groups["unifi_protect"]
            - inventory_hostname not in groups["amp"] | default([])

        - name: Get backup archive file size for {{ inventory_hostname }}
          ansible.builtin.stat:
            path: "{{ backup_tmp_file }}"
          register: file_size
          changed_when: false
          when:
            - inventory_hostname not in groups["docker_stacks"] | default([])
            - inventory_hostname not in groups["amp"] | default([])

        # ===== START DOCKER =====
        - include_tasks: tasks/docker_start.yaml
          vars:
            _docker_wait_ssh: true
          when:
            - inventory_hostname not in groups["docker_stacks"] | default([])
            - inventory_hostname in groups["docker_run"] | default([])
            - config_file == 'docker_run'

        # ===== FETCH AND CLEANUP =====
        - name: Delete prior backup archive for {{ inventory_hostname }} on controller
          ansible.builtin.file:
            path: "{{ backup_dest_path }}"
            state: absent
          delegate_to: localhost
          become: false
          when:
            - inventory_hostname not in groups["docker_stacks"] | default([])
            - inventory_hostname not in groups["amp"] | default([])

        - name: Fetch backup archive for {{ inventory_hostname }} to controller
          ansible.builtin.fetch:
            src: "{{ backup_tmp_file }}"
            dest: "{{ backup_dest_path }}"
            flat: true
          become: false
          when:
            - inventory_hostname not in groups["docker_stacks"] | default([])
            - inventory_hostname not in groups["amp"] | default([])

        - name: Delete source backup on {{ inventory_hostname }}
          become: true
          ansible.builtin.file:
            path: "{{ backup_tmp_file }}"
            state: absent
          when:
            - inventory_hostname not in groups["docker_stacks"] | default([])
            - inventory_hostname not in groups["amp"] | default([])

      rescue:
        - name: Set backup failed flag for {{ inventory_hostname }}
          ansible.builtin.set_fact:
            backup_failed: true

      always:
        # ===== SAFETY NET: ENSURE DOCKER IS RUNNING =====
        - include_tasks: tasks/docker_start.yaml
          vars:
            _docker_ignore_errors: true
          when:
            - inventory_hostname in groups["docker_run"] | default([])
            - config_file == 'docker_run'

        # ===== WAIT FOR MARIADB AFTER DOCKER RESTART =====
        - name: Wait for MariaDB logging database after Docker restart
          vars:
            ansible_python_interpreter: "{{ ansible_playbook_python }}"
          become: false
          connection: local
          community.mysql.mysql_query:
            login_host: "{{ logging_db_host }}"
            login_port: "{{ logging_db_port }}"
            login_user: "{{ logging_db_user }}"
            login_password: "{{ logging_db_password }}"
            login_db: "{{ logging_db_name }}"
            query: "SELECT 1"
          register: _mariadb_post_restart
          retries: 40
          delay: 10
          until: _mariadb_post_restart is succeeded
          when: inventory_hostname in groups["docker_stacks"] or inventory_hostname in groups["docker_run"]
          changed_when: false
          no_log: "{{ not (debug_no_log | default(false) | bool) and (ansible_verbosity | default(0) | int < 3) }}"
          check_mode: false
          ignore_errors: true

        # ===== COMBINED DB BACKUP (when with_databases=yes) =====
        - name: Initialize combined DB backup state (when with_databases)
          ansible.builtin.set_fact:
            _db_combined_results: []
            _combined_db_failed: false
          when:
            - with_databases | default('') == 'yes'
            - inventory_hostname in groups["docker_stacks"] | default([]) or
              inventory_hostname in groups["docker_run"] | default([])

        # Evaluate the guard once as a local fact. Block when: is re-evaluated
        # per task — if the flag-set were inside the block, subsequent tasks
        # would see _combined_db_done=true and skip.
        - name: Check if combined DB backup should run on this batch
          ansible.builtin.set_fact:
            _should_run_combined_db: >-
              {{ with_databases | default('') == 'yes'
                 and (inventory_hostname in groups["docker_stacks"] | default([])
                      or inventory_hostname in groups["docker_run"] | default([]))
                 and not (hostvars['localhost']['_combined_db_done'] | default(false))
                 and not ansible_check_mode }}

        - name: Mark combined DB backup as started
          ansible.builtin.set_fact:
            _combined_db_done: true
          delegate_to: localhost
          delegate_facts: true
          when: _should_run_combined_db | bool

        - name: Run combined database backups (all groups)
          when: _should_run_combined_db | bool
          block:
            - name: Back up all database groups
              include_tasks: tasks/backup_combined_db_group.yaml
              loop: "{{ combined_db_configs }}"
              loop_control:
                loop_var: _db_config_file

          rescue:
            - name: Set combined DB backup failed flag (rescue)
              ansible.builtin.set_fact:
                _combined_db_failed: true

        # ===== REPORTING (per-stack) =====
        - name: Build per-stack notification fields for backup results
          ansible.builtin.set_fact:
            _stack_discord_fields: >-
              [
               {% for r in _stack_backup_results %}
               {% if not loop.first %},{% endif %}
               {"name": "{{ ('❌ ' if r.failed else '✅ ') + r.stack }}", "value": "{{ 'FAILED' if r.failed else ('empty' if r.file_size == 0 else ((r.file_size / 1024 / 1024) | round(2) | string + ' MB')) }}", "inline": true}
               {% endfor %}]
          when: inventory_hostname in groups["docker_stacks"] | default([])

        - name: Send per-stack backup notification
          include_tasks: tasks/notify.yaml
          vars:
            discord_name: "{{ _original_backup_name }}"
            discord_operation: "Backup"
            discord_status: >-
              {{ 'successful' if not (backup_failed | bool)
                 else ('failed' if (_stack_backup_results | rejectattr('failed') | list | length == 0)
                       else 'partial') }}
            discord_color: >-
              {{ discord_color_success if not (backup_failed | bool)
                 else (discord_color_failure if (_stack_backup_results | rejectattr('failed') | list | length == 0)
                       else discord_color_warning) }}
            discord_url: "{{ _original_backup_url }}"
            discord_fields: "{{ _stack_discord_fields }}"
          when: inventory_hostname in groups["docker_stacks"] | default([])

        # ===== REPORTING (per-AMP-instance) =====
        - name: Build per-instance AMP notification fields for backup results
          ansible.builtin.set_fact:
            _amp_discord_fields: >-
              [
               {% for r in _amp_backup_results %}
               {% if not loop.first %},{% endif %}
               {"name": "{{ ('❌ ' if r.failed else '✅ ') + r.instance }}", "value": "{{ 'FAILED' if r.failed else ('empty' if r.file_size == 0 else ((r.file_size / 1024 / 1024) | round(2) | string + ' MB')) }}", "inline": true}
               {% endfor %}]
          when: inventory_hostname in groups["amp"] | default([])

        - name: Send per-instance AMP backup notification
          include_tasks: tasks/notify.yaml
          vars:
            discord_name: "{{ backup_name }}"
            discord_operation: "Backup"
            discord_status: >-
              {{ 'successful' if not (backup_failed | bool)
                 else ('failed' if (_amp_backup_results | rejectattr('failed') | list | length == 0)
                       else 'partial') }}
            discord_color: >-
              {{ discord_color_success if not (backup_failed | bool)
                 else (discord_color_failure if (_amp_backup_results | rejectattr('failed') | list | length == 0)
                       else discord_color_warning) }}
            discord_url: "{{ _original_backup_url }}"
            discord_fields: "{{ _amp_discord_fields }}"
          when: inventory_hostname in groups["amp"] | default([])

        # ===== REPORTING (monolithic) =====
        - name: Send monolithic backup notification
          include_tasks: tasks/notify.yaml
          vars:
            discord_name: "{{ backup_name }}"
            discord_operation: "Backup"
            discord_status: "{{ 'failed' if backup_failed else 'successful' }}"
            discord_color: "{{ discord_color_failure if backup_failed else discord_color_success }}"
            discord_url: "{{ _original_backup_url }}"
            discord_fields:
              - name: "Stacks"
                value: "{{ stack_assignments[inventory_hostname] | default([]) | join(', ') }}"
              - name: "Backup Name"
                value: "{{ backup_file }}"
              - name: "Backup Size"
                value: "{{ (file_size.stat.size / 1024 / 1024) | round(2) }}MB"
          when:
            - inventory_hostname not in groups["docker_stacks"] | default([])
            - inventory_hostname not in groups["amp"] | default([])
            - inventory_hostname not in groups["unifi_protect"]  # TODO: file retrieval broken — silence until fixed

        - name: Send Docker recovery failure alert
          include_tasks: tasks/notify.yaml
          when:
            - backup_failed | bool
            - (_docker_start_stacks is defined and _docker_start_stacks is failed) or
              (_docker_start_containers is defined and _docker_start_containers is failed)
          vars:
            discord_name: "{{ _original_backup_name }}"
            discord_operation: "Backup"
            discord_status: "failed"
            discord_detail: "containers could not be restarted"
            discord_color: "{{ discord_color_failure }}"
            discord_url: "{{ _original_backup_url }}"
            discord_fields:
              - name: "Docker Recovery"
                value: "Manual intervention required"

        # ===== REPORTING (combined DB) =====
        - name: Build combined DB notification fields for backup results
          ansible.builtin.set_fact:
            _db_discord_fields: >-
              [
               {% for r in _db_combined_results %}
               {% if not loop.first %},{% endif %}
               {"name": "{{ ('❌ ' if r.backup_rc != 0 else '✅ ') + r.db_name }}", "value": "{{ 'FAILED' if r.backup_rc != 0 else ((r.file_size / 1024 / 1024) | round(2) | string + ' MB') }}", "inline": true}
               {% endfor %}]
          when: _db_combined_results | default([]) | length > 0

        - name: Send combined DB backup notification
          include_tasks: tasks/notify.yaml
          vars:
            discord_name: "Database"
            discord_operation: "Backup"
            discord_author: "Databases"
            discord_status: >-
              {{ 'successful' if (_db_combined_results | selectattr('backup_rc', 'ne', 0) | list | length == 0)
                 else ('failed' if (_db_combined_results | selectattr('backup_rc', 'eq', 0) | list | length == 0)
                       else 'partial') }}
            discord_color: >-
              {{ discord_color_success if (_db_combined_results | selectattr('backup_rc', 'ne', 0) | list | length == 0)
                 else (discord_color_failure if (_db_combined_results | selectattr('backup_rc', 'eq', 0) | list | length == 0)
                       else discord_color_warning) }}
            discord_url: "https://sql.{{ domain_ext }}"
            discord_fields: "{{ _db_discord_fields }}"
          when: _db_combined_results | default([]) | length > 0

        - name: Send combined DB unhandled failure notification
          include_tasks: tasks/notify.yaml
          when:
            - _combined_db_failed | default(false)
            - _db_combined_results | default([]) | length == 0
          vars:
            discord_name: "Database"
            discord_operation: "Backup"
            discord_status: "failed"
            discord_detail: "check Semaphore logs"
            discord_color: "{{ discord_color_failure }}"
            discord_url: "https://sql.{{ domain_ext }}"

        - name: Clean up UNVR temp backup file
          ansible.builtin.file:
            path: "{{ unifi_protect_temp_file }}"
            state: absent
          delegate_to: localhost
          when: inventory_hostname in groups["unifi_protect"]

        # ===== MARIADB LOGGING (per-stack — one row per stack) =====
        - name: Log per-stack backups to MariaDB
          include_tasks: tasks/log_mariadb.yaml
          loop: "{{ _stack_backup_results }}"
          loop_control:
            loop_var: _stack_result
          vars:
            log_table: backups
            log_application: "{{ _stack_result.stack }}"
            log_hostname: "{{ inventory_hostname }}"
            log_file_name: "{{ ('FAILED_' if _stack_result.failed else '') + _stack_result.file }}"
            log_file_size: "{{ (_stack_result.file_size / 1024 / 1024) | round(2) }}"
            log_backup_level: "stack"
          when: inventory_hostname in groups["docker_stacks"] | default([])

        # ===== MARIADB LOGGING (per-AMP-instance — one row per instance) =====
        - name: Log per-instance AMP backups to MariaDB
          include_tasks: tasks/log_mariadb.yaml
          loop: "{{ _amp_backup_results }}"
          loop_control:
            loop_var: _amp_result
          vars:
            log_table: backups
            log_application: "{{ backup_name }} — {{ _amp_result.instance }}"
            log_hostname: "{{ inventory_hostname }}"
            log_file_name: "{{ ('FAILED_' if _amp_result.failed else '') + _amp_result.file }}"
            log_file_size: "{{ (_amp_result.file_size / 1024 / 1024) | round(2) }}"
            log_backup_level: "instance"
          when: inventory_hostname in groups["amp"] | default([])

        # ===== MARIADB LOGGING (monolithic — single row) =====
        - name: Log monolithic backup to MariaDB for {{ inventory_hostname }}
          include_tasks: tasks/log_mariadb.yaml
          vars:
            log_table: backups
            log_application: "{{ backup_name }}"
            log_hostname: "{{ inventory_hostname }}"
            log_file_name: "{{ ('FAILED_' if backup_failed else '') + backup_file }}"
            log_file_size: "{{ (file_size.stat.size / 1024 / 1024) | round(2) }}"
            log_backup_level: "host"
          when:
            - inventory_hostname not in groups["docker_stacks"] | default([])
            - inventory_hostname not in groups["amp"] | default([])
            - inventory_hostname not in groups["unifi_protect"]  # TODO: file retrieval broken — silence until fixed

        # ===== MARIADB LOGGING (combined DB — one row per database) =====
        - name: Log combined DB backup results to MariaDB
          include_tasks: tasks/log_mariadb.yaml
          loop: "{{ _db_combined_results | default([]) }}"
          loop_control:
            loop_var: _db_result
          vars:
            log_table: backups
            log_application: "{{ _db_result.db_name }}-db"
            log_hostname: "{{ _db_result.db_host }}"
            log_file_name: "{{ ('FAILED_' if _db_result.backup_rc != 0 else '') + _db_result.file_name }}"
            log_file_size: "{{ (_db_result.file_size / 1024 / 1024) | round(2) if _db_result.backup_rc == 0 else 0 }}"
            log_backup_level: "db"
          when: _db_combined_results | default([]) | length > 0

        # ===== CLEANUP RUN-SCOPED TEMP DIRECTORY =====
        - name: Remove run-scoped temp directory
          become: true
          ansible.builtin.file:
            state: absent
            path: "{{ backup_tmp_dir }}"
          when: "'/run_' in backup_tmp_dir"

        # ===== PiKVM: RETURN TO READ-ONLY =====
        - name: Put PiKVM device back in RO mode (post-backup)
          raw: ro
          when:
            - inventory_hostname in groups["pikvm"]
            - not ansible_check_mode
